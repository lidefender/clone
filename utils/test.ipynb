{
 "cells": [
  {
   "cell_type": "raw",
   "id": "26ce96feff5efd44",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "importimport sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ctypes import *\n",
    "\n",
    "# 添加 MVS SDK 的 Python 包路径\n",
    "sys.path.append(r\"F:\\install\\MVS\\Development\\Samples\\Python\\MvImport\")\n",
    "\n",
    "# 导入 MVS SDK\n",
    "from MvCameraControl_class import *\n",
    "\n",
    "def main():\n",
    "    # 创建相机对象\n",
    "    cam = MvCamera()\n",
    "\n",
    "    # 设备信息列表\n",
    "    deviceList = MV_CC_DEVICE_INFO_LIST()\n",
    "    tlayerType = MV_GIGE_DEVICE | MV_USB_DEVICE\n",
    "\n",
    "    # 枚举设备\n",
    "    ret = cam.MV_CC_EnumDevices(tlayerType, byref(deviceList))\n",
    "    if ret != 0:\n",
    "        print(f\"Enum devices failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    if deviceList.nDeviceNum == 0:\n",
    "        print(\"No devices found!\")\n",
    "        return\n",
    "\n",
    "# 确保调用 main 函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T02:30:25.525334Z",
     "start_time": "2024-07-02T02:30:20.628886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ],
   "id": "56f55fb497690c24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ed21efff4ff6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T09:28:55.890421Z",
     "start_time": "2024-07-01T09:28:55.033647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No camera found at index 1\n",
      "No camera found at index 3\n",
      "No camera found at index 5\n",
      "No camera found at index 7\n",
      "No camera found at index 9\n",
      "No camera found at index 11\n",
      "No camera found at index 13\n",
      "No camera found at index 15\n",
      "No camera found at index 17\n",
      "No camera found at index 19\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "index = 1 # 从第一个设备开始检查\n",
    "cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)  # 使用CAP_DSHOW可以避免一些兼容性问题\n",
    "while index<20:\n",
    "    # 尝试打开当前索引对应的设备\n",
    "    cap.open(index, cv2.CAP_DSHOW)\n",
    "    \n",
    "    # 检查是否成功打开设备\n",
    "    \n",
    "    if cap.isOpened():\n",
    "        print(f\"Camera found at index {index}\")\n",
    "        # 在这里可以做一些操作，比如获取帧并显示\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow('Camera', frame)  # 显示相机捕获的第一帧\n",
    "            cv2.waitKey(0)  # 等待键盘输入\n",
    "            break\n",
    "    else:\n",
    "        print(f\"No camera found at index {index}\")\n",
    "    cap.release()  # 释放设备\n",
    "    index+=1\n",
    "\n",
    "    index += 1  # 检查下一个设备\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(7)  #调用摄像头‘0’一般是打开电脑自带摄像头，其他值是打开外部摄像头（只有一个摄像头的情况）\n",
    " \n",
    "if False == cap.isOpened():\n",
    "    print(0)\n",
    "else:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fea526b9bc10cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T09:28:55.920964Z",
     "start_time": "2024-07-01T09:28:55.891933Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\work\\\\python\\\\clone\\\\2d\\\\Pytorch-UNet\\\\data\\\\imgs\\\\sample\\\\Image_20240622155143140_OUT.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m----> 4\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mwork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mclone\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m2d\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mPytorch-UNet\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mimgs\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124msample\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mImage_20240622155143140_OUT.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(img)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\PIL\\Image.py:3247\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3244\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[0;32m   3246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3247\u001B[0m     fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3248\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'F:\\\\work\\\\python\\\\clone\\\\2d\\\\Pytorch-UNet\\\\data\\\\imgs\\\\sample\\\\Image_20240622155143140_OUT.png'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "img = Image.open(r'F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\sample\\Image_20240622155143140_OUT.png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70627fb4f3020698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T09:28:55.920964Z",
     "start_time": "2024-07-01T09:28:55.920964Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1=cv2.imread(r'F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\sample\\barsample1_OUT.png')\n",
    "print(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b9287c2f2d0628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T12:43:27.519429Z",
     "start_time": "2024-06-27T12:43:26.189985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e148cb4cff4caca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T09:36:44.108757Z",
     "start_time": "2024-06-25T09:36:41.848414Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model FILE] [--input INPUT [INPUT ...]]\n",
      "                             [--output OUTPUT [OUTPUT ...]] [--viz]\n",
      "                             [--no-save] [--mask-threshold MASK_THRESHOLD]\n",
      "                             [--scale SCALE] [--bilinear] [--classes CLASSES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Liminghui\\AppData\\Roaming\\jupyter\\runtime\\kernel-b15d4986-7d81-481e-a485-73882b6175e1.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\work\\environment\\envs\\bar\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data_loading import BasicDataset\n",
    "from unet import UNet\n",
    "from utils.utils import plot_img_and_mask\n",
    "\n",
    "def predict_img(net, full_img, device, scale_factor=1, out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "    logging.info(f'Preprocessed image shape: {img.shape}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "        output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "    logging.info(f'Predicted mask unique values: {torch.unique(mask)}')\n",
    "    return mask[0].long().squeeze().numpy()\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Predict mask from input images')\n",
    "    parser.add_argument('--model', '-m', default='2d/Pytorch-UNet/model/checkpoint_epoch10.pth', metavar='FILE',\n",
    "                        help='Specify the file in which the model is stored')\n",
    "    parser.add_argument('--input', '-i', metavar='INPUT', nargs='+', help='Filenames of input images')\n",
    "    parser.add_argument('--output', '-o', metavar='OUTPUT', nargs='+', help='Filenames of output images')\n",
    "    parser.add_argument('--viz', '-v', action='store_true',\n",
    "                        help='Visualize the images as they are processed')\n",
    "    parser.add_argument('--no-save', '-n', action='store_true', help='Do not save the output mask')\n",
    "    parser.add_argument('--mask-threshold', '-t', type=float, default=0.5,\n",
    "                        help='Minimum probability value to consider a mask pixel white')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5,\n",
    "                        help='Scale factor for the input images')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.input is None:\n",
    "        args.input = [r'F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\barsample.jpg']\n",
    "\n",
    "    return args\n",
    "\n",
    "def get_output_filenames(args):\n",
    "    def _generate_name(fn):\n",
    "        return f'{os.path.splitext(fn)[0]}_OUT.png'\n",
    "    return args.output or list(map(_generate_name, args.input))\n",
    "\n",
    "def mask_to_image(mask: np.ndarray, mask_values):\n",
    "    logging.info(f'Mask shape: {mask.shape}, unique values: {np.unique(mask)}')\n",
    "    if isinstance(mask_values[0], list):\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1], len(mask_values[0])), dtype=np.uint8)\n",
    "    elif mask_values == [0, 1]:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=bool)\n",
    "    else:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.uint8)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = np.argmax(mask, axis=0)\n",
    "\n",
    "    for i, v in enumerate(mask_values):\n",
    "        out[mask == i] = v\n",
    "\n",
    "    return Image.fromarray(out)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "\n",
    "    img_dir = r\"F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\sample\"\n",
    "    fname = os.listdir(img_dir)\n",
    "    for name in fname:\n",
    "        fname2 = os.path.join(img_dir, name)\n",
    "        if args.input is None:\n",
    "            args.input = [fname2]\n",
    "        else:\n",
    "            args.input.append(fname2)\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "    in_files = args.input\n",
    "    out_files = get_output_filenames(args)\n",
    "\n",
    "    net = UNet(n_channels=3, n_classes=args.classes, bilinear=args.bilinear)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Loading model {args.model}')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    state_dict = torch.load(args.model, map_location=device)\n",
    "    logging.info(f'Model loaded with parameters: {list(net.parameters())[0].data}')\n",
    "    mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    logging.info('Model loaded!')\n",
    "\n",
    "    for i, filename in enumerate(in_files):\n",
    "        logging.info(f'Predicting image {filename} ...')\n",
    "        img = Image.open(filename)\n",
    "\n",
    "        mask = predict_img(net=net,\n",
    "                           full_img=img,\n",
    "                           scale_factor=args.scale,\n",
    "                           out_threshold=args.mask_threshold,\n",
    "                           device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b91de7ba3d4792e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T09:50:23.134709Z",
     "start_time": "2024-06-26T09:50:15.785625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152006003_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152022155_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152027051_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152032646_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152038023_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152043066_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152049220_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152054365_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152100108_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152105224_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152110857_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152117110_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152138391_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152201002_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152327307_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152413746_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152525162_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152527929_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152530118_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152532671_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152535159_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152537569_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152540884_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152552400_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152555962_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152559960_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152602787_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152606947_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152609327_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152612356_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152614649_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152624069_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152628099_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152631231_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152634116_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152637110_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152639961_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152642626_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152645923_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152648476_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152651019_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152653778_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152656210_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152658379_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622152700696_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153200523_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153209279_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153212685_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153214873_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153218585_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153221036_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153223271_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153226221_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153251975_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153254754_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153257949_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153650303_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153653586_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153656245_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622153700003_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154405623_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154413899_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154418470_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154424228_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154427379_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154433081_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154435984_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154446120_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154601873_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154620468_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154623657_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154626429_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154631970_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154639550_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154641938_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154646176_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154649319_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154651792_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154654311_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154658031_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154706390_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154709489_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154712309_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154812990_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154819654_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154821973_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154827145_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154832033_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154836747_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154848851_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154851267_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154857968_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154900145_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154903985_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154906938_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154910728_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622154916381_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155007334_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155016309_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155021647_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155029176_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155032006_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155034689_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155038553_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155041962_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155044252_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155046691_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155050622_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155053314_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155056422_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155059256_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155111106_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155114550_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155118711_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155122322_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155125003_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155143140_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155150771_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155153563_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155159115_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155217456_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155222760_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155227334_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155232385_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155236881_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155242684_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155245361_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155449132_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155453216_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155455613_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155459067_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155503938_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155514810_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155518451_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155627318_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155634193_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155638304_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155643472_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155648213_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155652944_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155658642_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155702237_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155706238_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155713170_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155716771_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155719377_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155722311_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155724819_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155727835_mask.png\n",
      "最高灰度值: 1\n",
      "新图像已保存到: F:\\work\\dataset\\rebar2D\\train2\\TEMP\\Image_20240622155730477_mask.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_max_gray_value(image_path):\n",
    "    # 打开图像\n",
    "    img = Image.open(image_path).convert('L')  # 转换为灰度图像\n",
    "\n",
    "    # 转换为numpy数组\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # 获取最高灰度值\n",
    "    max_gray_value = img_array.max()\n",
    "    print(f\"最高灰度值: {max_gray_value}\")\n",
    "\n",
    "    return img_array, img\n",
    "\n",
    "def replace_gray_value(img_array, old_value, new_value):\n",
    "    # 将灰度值为old_value的像素转换为new_value\n",
    "    img_array[img_array == old_value] = new_value\n",
    "\n",
    "    # 转换为图像\n",
    "    new_img = Image.fromarray(img_array)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 替换为您的图片路径\n",
    "    # image_path = 'path_to_your_image.png'\n",
    "    image_path = r\"F:\\work\\dataset\\rebar2D\\train2\\mask\"\n",
    "    output_dir = r\"F:\\work\\dataset\\rebar2D\\train2\\TEMP\"\n",
    "    for filename in os.listdir(image_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            input_path = os.path.join(image_path, filename)\n",
    "            # 获取最高灰度值并返回图像数组\n",
    "            img_array, img = get_max_gray_value(input_path)\n",
    "\n",
    "            # 将灰度值为1的像素转换为255\n",
    "            new_img = replace_gray_value(img_array, 1, 255)\n",
    "\n",
    "            # 保存新图像\n",
    "            new_image_path = os.path.join(output_dir, filename)\n",
    "            new_img.save(new_image_path)\n",
    "            print(f\"新图像已保存到: {new_image_path}\")\n",
    "    # # 获取最高灰度值并返回图像数组\n",
    "    # img_array, img = get_max_gray_value(\"/kaggle/input/rebar2d/train2/mask/Image_20240622152006003_mask.png\")\n",
    "    # \n",
    "    # # 将灰度值为1的像素转换为255\n",
    "    # new_img = replace_gray_value(img_array, 1, 255)\n",
    "    # \n",
    "    # # 保存新图像\n",
    "    # new_image_path = 'path_to_save_new_image.png'\n",
    "    # new_img.save(new_image_path)\n",
    "    # print(f\"新图像已保存到: {new_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98c447c340d7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db212dbad73f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from labelme import utils\n",
    "from PIL import Image\n",
    "\n",
    "def labelme_to_yolov8(labelme_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"labels\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"masks\"), exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(labelme_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = os.path.join(labelme_dir, filename)\n",
    "            with open(json_path) as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            image_data = utils.img_b64_to_arr(data['imageData'])\n",
    "            img = Image.fromarray(image_data)\n",
    "            img.save(os.path.join(output_dir, \"images\", filename.replace(\".json\", \".jpg\")))\n",
    "\n",
    "            shapes = data['shapes']\n",
    "            mask = np.zeros(image_data.shape[:2], dtype=np.uint8)\n",
    "\n",
    "            for shape in shapes:\n",
    "                points = np.array(shape['points'], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points], color=1)\n",
    "            \n",
    "            mask_img = Image.fromarray(mask * 255)\n",
    "            mask_img.save(os.path.join(output_dir, \"masks\", filename.replace(\".json\", \".png\")))\n",
    "\n",
    "            label_path = os.path.join(output_dir, \"labels\", filename.replace(\".json\", \".txt\"))\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"{filename.replace('.json', '')} {mask_path.replace('.json', '.png')}\\n\")\n",
    "\n",
    "# 使用示例\n",
    "labelme_dir = \"path/to/labelme/json\"\n",
    "output_dir = \"path/to/yolov8/dataset\"\n",
    "labelme_to_yolov8(labelme_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59228400591776a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:41:37.055507Z",
     "start_time": "2024-06-28T08:38:45.593809Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # 导入操作系统模块\n",
    "import json  # 导入JSON模块\n",
    "\n",
    "def convert_json_to_txt_with_normalization_and_mapping(labelme_dir, output_dir, label_mapping):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # 创建输出目录，如果不存在则创建\n",
    "    \n",
    "    json_files = [f for f in os.listdir(labelme_dir) if f.endswith('.json')]  # 获取目录下所有JSON文件的列表\n",
    "    \n",
    "    for filename in json_files:  # 遍历每个JSON文件\n",
    "        json_path = os.path.join(labelme_dir, filename)  # 构建JSON文件的完整路径\n",
    "        txt_filename = filename.replace('.json', '.txt')  # 构建输出TXT文件的文件名\n",
    "        txt_path = os.path.join(output_dir, txt_filename)  # 构建输出TXT文件的完整路径\n",
    "        \n",
    "        with open(json_path) as f:  # 打开JSON文件\n",
    "            data = json.load(f)  # 加载JSON数据\n",
    "        \n",
    "        image_height = data['imageHeight']  # 获取图像的高度\n",
    "        image_width = data['imageWidth']  # 获取图像的宽度\n",
    "        \n",
    "        with open(txt_path, 'w') as f:  # 打开（或创建）TXT文件以写入模式\n",
    "            for shape in data['shapes']:  # 遍历每个形状\n",
    "                label = shape['label']  # 获取形状的标签\n",
    "                points = shape['points']  # 获取形状的坐标点\n",
    "                normalized_points = [(x / image_width, y / image_height) for x, y in points]  # 归一化坐标点\n",
    "                mapped_label = label_mapping.get(label, -1)  # 获取标签的映射值，默认为-1\n",
    "                \n",
    "                # 将标签和所有归一化后的坐标点写入TXT文件，一行表示一个实例\n",
    "                points_str = \" \".join([f\"{x:.6f} {y:.6f}\" for x, y in normalized_points])  # 将坐标点转换为字符串\n",
    "                f.write(f\"{mapped_label} {points_str}\\n\")  # 写入TXT文件\n",
    "\n",
    "# 使用示例\n",
    "labelme_dir = r\"F:\\work\\python\\clone\\dataset\\rebar2d\\labelme_jsons\"  # 指定Labelme JSON文件所在目录\n",
    "output_dir = r\"F:\\work\\python\\clone\\dataset\\rebar2d\\yololabel\"  # 指定输出的TXT文件目录\n",
    "label_mapping = {  # 标签映射字典\n",
    "    \"rebar\": 0\n",
    "    # 添加更多标签映射\n",
    "}\n",
    "convert_json_to_txt_with_normalization_and_mapping(labelme_dir, output_dir, label_mapping)  # 调用函数进行转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56247785712ef331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:23:46.071910Z",
     "start_time": "2024-06-28T10:23:44.909807Z"
    }
   },
   "outputs": [],
   "source": [
    "##划分数据集\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 定义函数以创建文件夹\n",
    "def make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# 定义数据集划分函数\n",
    "def split_dataset(image_dir, label_dir, output_dir, test_size=0.2, val_size=0.1, test_split=False):\n",
    "    # 创建输出目录\n",
    "    make_dir(output_dir)\n",
    "    make_dir(os.path.join(output_dir, 'train'))\n",
    "    make_dir(os.path.join(output_dir, 'val'))\n",
    "    \n",
    "    if test_split:\n",
    "        make_dir(os.path.join(output_dir, 'test'))\n",
    "    \n",
    "    # 获取所有图像文件名\n",
    "    images = os.listdir(image_dir)\n",
    "    labels = os.listdir(label_dir)\n",
    "    \n",
    "    # 将文件名排序，以确保图像和标签对齐\n",
    "    images.sort()\n",
    "    labels.sort()\n",
    "    \n",
    "    # 划分训练集和临时集（包含验证集和可能的测试集）\n",
    "    train_images, temp_images, train_labels, temp_labels = train_test_split(images, labels, test_size=(val_size + test_size))\n",
    "    \n",
    "    # 划分验证集和测试集\n",
    "    if test_split:\n",
    "        val_images, test_images, val_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=(test_size / (val_size + test_size)))\n",
    "    else:\n",
    "        val_images, val_labels = temp_images, temp_labels\n",
    "\n",
    "    # 定义复制文件的函数\n",
    "    def copy_files(file_list, source_dir, dest_dir):\n",
    "        for file in file_list:\n",
    "            shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, file))\n",
    "    \n",
    "    # 复制训练集文件\n",
    "    copy_files(train_images, image_dir, os.path.join(output_dir, 'train'))\n",
    "    copy_files(train_labels, label_dir, os.path.join(output_dir, 'train'))\n",
    "    \n",
    "    # 复制验证集文件\n",
    "    copy_files(val_images, image_dir, os.path.join(output_dir, 'val'))\n",
    "    copy_files(val_labels, label_dir, os.path.join(output_dir, 'val'))\n",
    "\n",
    "    # 如果需要，复制测试集文件\n",
    "    if test_split:\n",
    "        copy_files(test_images, image_dir, os.path.join(output_dir, 'test'))\n",
    "        copy_files(test_labels, label_dir, os.path.join(output_dir, 'test'))\n",
    "\n",
    "# 示例使用\n",
    "# input_dir = r\"F:\\work\\python\\clone\\dataset\\rebar2d\\images\"  \n",
    "# output_dir = r\"F:\\work\\python\\clone\\2d\\ultralytics\\dataset\\rebar2d\"  \n",
    "image_dir = r\"F:\\work\\python\\clone\\dataset\\rebar2d\\images\"     # 图像目录路径\n",
    "label_dir = r'F:\\work\\python\\clone\\dataset\\rebar2d\\yololabel'   # 标签目录路径\n",
    "output_dir =  r\"F:\\work\\python\\clone\\2d\\ultralytics\\dataset\\rebar2d\"    # 输出目录路径\n",
    "\n",
    "split_dataset(image_dir, label_dir, output_dir, test_size=0.1, val_size=0, test_split=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7869c2c24ae2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from albumentations import (HorizontalFlip, VerticalFlip, RandomRotate90, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue, RandomBrightnessContrast, GaussNoise, Compose)\n",
    "from albumentations.core.serialization import save, load\n",
    "\n",
    "# 定义数据增强的函数\n",
    "def augment_data(image, mask):\n",
    "    # 定义增强变换\n",
    "    aug = Compose([\n",
    "        HorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "        VerticalFlip(p=0.5),    # 随机垂直翻转\n",
    "        RandomRotate90(p=0.5),  # 随机旋转90度\n",
    "        ShiftScaleRotate(scale_limit=0.2, rotate_limit=45, shift_limit=0.1, p=0.5, border_mode=cv2.BORDER_REFLECT),\n",
    "        Blur(blur_limit=3, p=0.2),  # 模糊\n",
    "        OpticalDistortion(distort_limit=0.3, p=0.5),\n",
    "        GridDistortion(p=0.5),\n",
    "        HueSaturationValue(p=0.5),  # 色调饱和度变化\n",
    "        RandomBrightnessContrast(p=0.5),  # 随机亮度对比度\n",
    "        GaussNoise(p=0.2)  # 高斯噪声\n",
    "    ])\n",
    "    \n",
    "    # 应用增强变换\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "    return augmented['image'], augmented['mask']\n",
    "\n",
    "# 定义处理单个文件的函数\n",
    "def process_file(image_path, mask_path, output_image_dir, output_mask_dir, num_augments=5):\n",
    "    # 读取图像和标签\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # 标签通常是灰度图\n",
    "    \n",
    "    for i in range(num_augments):\n",
    "        # 增强数据\n",
    "        aug_image, aug_mask = augment_data(image, mask)\n",
    "        \n",
    "        # 生成文件名\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        image_save_path = os.path.join(output_image_dir, f\"{base_name}_aug_{i}.png\")\n",
    "        mask_save_path = os.path.join(output_mask_dir, f\"{base_name}_aug_{i}.png\")\n",
    "        \n",
    "        # 保存增强后的图像和标签\n",
    "        cv2.imwrite(image_save_path, aug_image)\n",
    "        cv2.imwrite(mask_save_path, aug_mask)\n",
    "\n",
    "# 定义处理整个目录的函数\n",
    "def process_directory(image_dir, mask_dir, output_image_dir, output_mask_dir, num_augments=5):\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_image_dir, exist_ok=True)\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "    \n",
    "    # 获取所有图像文件\n",
    "    image_files = os.listdir(image_dir)\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        mask_path = os.path.join(mask_dir, image_file)  # 假设图像和标签文件名相同\n",
    "        \n",
    "        if os.path.exists(mask_path):\n",
    "            process_file(image_path, mask_path, output_image_dir, output_mask_dir, num_augments)\n",
    "\n",
    "# 示例使用\n",
    "image_dir = 'path/to/images'        # 原始图像目录\n",
    "label_dir = 'path/to/labels'        # 原始标签目录\n",
    "output_image_dir = 'path/to/augmented_images'  # 增强后的图像目录\n",
    "output_label_dir = 'path/to/augmented_labels'  # 增强后的标签目录\n",
    "\n",
    "# 处理整个目录\n",
    "process_directory(image_dir, label_dir, output_image_dir, output_label_dir, num_augments=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7dba3f50a631d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T01:45:09.961846Z",
     "start_time": "2024-06-29T01:45:09.935645Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2  # 导入OpenCV库\n",
    "import json  # 导入JSON库\n",
    "import numpy as np  # 导入NumPy库\n",
    "\n",
    "def generate_json_from_mask(mask_path, json_path, label):\n",
    "    # 读取掩码图像\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # 查找图像中的轮廓\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 确保找到至少一个轮廓\n",
    "    if len(contours) == 0:\n",
    "        raise ValueError(\"No contours found in mask image\")\n",
    "\n",
    "    # 只取最大的轮廓\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # 将轮廓坐标转换为列表\n",
    "    contour_list = contour.squeeze().tolist()\n",
    "    \n",
    "    # 检查并处理单点情况\n",
    "    if isinstance(contour_list[0], int):\n",
    "        contour_list = [contour_list]\n",
    "    \n",
    "    # 创建标签数据结构\n",
    "    data = {\n",
    "        \"label\": label,\n",
    "        \"points\": contour_list\n",
    "    }\n",
    "    \n",
    "    # 将数据写入JSON文件\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# 示例使用\n",
    "mask_path = r\"F:\\work\\dataset\\rebar2D\\train\\TEMP\\Image_20240622152022155.png\"  # 掩码图像路径\n",
    "json_path = r\"F:\\work\\dataset\\rebar2D\\train\\jsontest\\jsontest.json\"  # 输出JSON文件路径\n",
    "label = 'rebar'  # 目标标签\n",
    "\n",
    "# 调用函数生成JSON文件\n",
    "generate_json_from_mask(mask_path, json_path, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c333f263f7ca0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T02:10:00.478018Z",
     "start_time": "2024-06-29T02:09:57.902101Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2  # 导入OpenCV库\n",
    "import json  # 导入JSON库\n",
    "import numpy as np  # 导入NumPy库\n",
    "import os  # 导入os库，用于文件和目录操作\n",
    "\n",
    "def generate_json_from_mask(mask_path, json_path, label):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # 读取掩码图像\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # 查找图像中的轮廓\n",
    "\n",
    "    if len(contours) == 0:  # 确保找到至少一个轮廓\n",
    "        raise ValueError(f\"No contours found in {mask_path}\")\n",
    "\n",
    "    contour = max(contours, key=cv2.contourArea)  # 只取最大的轮廓\n",
    "    contour_list = contour.squeeze().tolist()  # 将轮廓坐标转换为列表\n",
    "\n",
    "    if isinstance(contour_list[0], int):  # 检查并处理单点情况\n",
    "        contour_list = [contour_list]\n",
    "\n",
    "    # 创建标签数据结构\n",
    "    data = {\n",
    "        \"shapes\": [\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"points\": contour_list,\n",
    "                \"group_id\": None,\n",
    "                \"description\": \"\",\n",
    "                \"shape_type\": \"polygon\",\n",
    "                \"flags\": {},\n",
    "                \"mask\": None\n",
    "            }\n",
    "        ],\n",
    "        \"imagePath\": mask_path,\n",
    "        \"imageData\": None,\n",
    "        \"imageHeight\": mask.shape[0],\n",
    "        \"imageWidth\": mask.shape[1]\n",
    "    }\n",
    "\n",
    "    with open(json_path, 'w') as json_file:  # 将数据写入JSON文件\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def process_masks_in_directory(directory, label):\n",
    "    for filename in os.listdir(directory):  # 遍历目录中的所有文件\n",
    "        if filename.endswith('.png'):  # 只处理PNG文件\n",
    "            mask_path = os.path.join(directory, filename)  # 构建掩码图像路径\n",
    "            json_path = os.path.splitext(mask_path)[0] + '.json'  # 构建JSON文件路径\n",
    "            generate_json_from_mask(mask_path, json_path, label)  # 调用函数生成JSON文件\n",
    "\n",
    "# 示例使用\n",
    "directory = r\"F:\\work\\dataset\\rebar2D\\train\\TEMP\"   # 掩码图像文件夹路径\n",
    "# mask_path = r\"F:\\work\\dataset\\rebar2D\\train\\TEMP\\Image_20240622152022155.png\"  # 掩码图像路径\n",
    "# json_path = r\"F:\\work\\dataset\\rebar2D\\train\\jsontest\\jsontest.json\"  # 输出JSON文件路径\n",
    "label = 'rebar'  # 目标标签\n",
    "\n",
    "process_masks_in_directory(directory, label)  # 处理目录中的所有掩码文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612365f35242764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5454f159bf55f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T02:58:04.107214Z",
     "start_time": "2024-06-30T02:58:03.437709Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 86\u001B[0m\n\u001B[0;32m     83\u001B[0m output_image_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mwork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mrebar2D\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mimg1\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# 输出图像文件夹路径\u001B[39;00m\n\u001B[0;32m     84\u001B[0m output_mask_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mwork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mrebar2D\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmask1\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# 输出掩码文件夹路径\u001B[39;00m\n\u001B[1;32m---> 86\u001B[0m process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder)\n",
      "Cell \u001B[1;32mIn[5], line 65\u001B[0m, in \u001B[0;36mprocess_folder\u001B[1;34m(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder)\u001B[0m\n\u001B[0;32m     62\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(image_path)  \u001B[38;5;66;03m# 读取图像\u001B[39;00m\n\u001B[0;32m     63\u001B[0m mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(mask_path, cv2\u001B[38;5;241m.\u001B[39mIMREAD_GRAYSCALE)  \u001B[38;5;66;03m# 读取掩码（灰度图像）\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m image_aug, mask_aug \u001B[38;5;241m=\u001B[39m augment_image(image, mask)  \u001B[38;5;66;03m# 对图像和掩码进行数据增强\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# 构建增强后图像和掩码的保存路径\u001B[39;00m\n\u001B[0;32m     68\u001B[0m output_image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_image_folder, image_file)\n",
      "Cell \u001B[1;32mIn[5], line 27\u001B[0m, in \u001B[0;36maugment_image\u001B[1;34m(image, mask)\u001B[0m\n\u001B[0;32m     14\u001B[0m transform \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m     15\u001B[0m     A\u001B[38;5;241m.\u001B[39mHorizontalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),  \u001B[38;5;66;03m# 水平翻转，概率为0.5\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     A\u001B[38;5;241m.\u001B[39mVerticalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),  \u001B[38;5;66;03m# 垂直翻转，概率为0.5\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m     A\u001B[38;5;241m.\u001B[39mRandomCrop(height\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, width\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m)  \u001B[38;5;66;03m# 随机裁剪到256x256，概率为1.0\u001B[39;00m\n\u001B[0;32m     24\u001B[0m ])\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# 应用数据增强到图像和掩码\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m augmented \u001B[38;5;241m=\u001B[39m transform(image\u001B[38;5;241m=\u001B[39mimage, mask\u001B[38;5;241m=\u001B[39mmask)\n\u001B[0;32m     28\u001B[0m image_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 增强后的图像\u001B[39;00m\n\u001B[0;32m     29\u001B[0m mask_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 增强后的掩码\u001B[39;00m\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:269\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m need_to_run:\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n\u001B[1;32m--> 269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(data)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m    272\u001B[0m     data \u001B[38;5;241m=\u001B[39m t(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:297\u001B[0m, in \u001B[0;36mCompose.preprocess\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_check_args:\n\u001B[1;32m--> 297\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_args(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    299\u001B[0m         p\u001B[38;5;241m.\u001B[39mensure_data_valid(data)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:362\u001B[0m, in \u001B[0;36mCompose._check_args\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m internal_data_name \u001B[38;5;129;01min\u001B[39;00m checked_single:\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m--> 362\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be numpy array type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    363\u001B[0m     shapes\u001B[38;5;241m.\u001B[39mappend(data\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m internal_data_name \u001B[38;5;129;01min\u001B[39;00m checked_multi \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data):\n",
      "\u001B[1;31mTypeError\u001B[0m: image must be numpy array type"
     ]
    }
   ],
   "source": [
    "import cv2  # 导入OpenCV库，用于图像处理\n",
    "import numpy as np  # 导入NumPy库，用于数值计算\n",
    "import albumentations as A  # 导入Albumentations库，用于数据增强\n",
    "import os  # 导入os模块，用于文件和目录操作\n",
    "\n",
    "def augment_image(image, mask):\n",
    "    \"\"\"\n",
    "    对输入的图像和掩码进行数据增强\n",
    "    :param image: 输入图像（H, W, C）\n",
    "    :param mask: 输入掩码（H, W）\n",
    "    :return: 增强后的图像和掩码\n",
    "    \"\"\"\n",
    "    # 定义数据增强流水线\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),  # 水平翻转，概率为0.5\n",
    "        A.VerticalFlip(p=0.5),  # 垂直翻转，概率为0.5\n",
    "        A.RandomRotate90(p=0.5),  # 随机旋转90度，概率为0.5\n",
    "        A.Transpose(p=0.5),  # 转置，概率为0.5\n",
    "        A.RandomBrightnessContrast(p=0.2),  # 随机亮度和对比度调整，概率为0.2\n",
    "        A.ElasticTransform(p=0.2),  # 弹性变换，概率为0.2\n",
    "        A.GridDistortion(p=0.2),  # 网格扭曲，概率为0.2\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.2),  # 平移、缩放和旋转，概率为0.2\n",
    "        A.RandomCrop(height=256, width=256, p=1.0)  # 随机裁剪到256x256，概率为1.0\n",
    "    ])\n",
    "    \n",
    "    # 应用数据增强到图像和掩码\n",
    "    augmented = transform(image=image, mask=mask)\n",
    "    image_aug = augmented['image']  # 增强后的图像\n",
    "    mask_aug = augmented['mask']  # 增强后的掩码\n",
    "    \n",
    "    return image_aug, mask_aug  # 返回增强后的图像和掩码\n",
    "\n",
    "def process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder):\n",
    "    \"\"\"\n",
    "    处理文件夹中的所有图像和掩码\n",
    "    :param input_image_folder: 输入图像文件夹路径\n",
    "    :param input_mask_folder: 输入掩码文件夹路径\n",
    "    :param output_image_folder: 输出图像文件夹路径\n",
    "    :param output_mask_folder: 输出掩码文件夹路径\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)  # 如果输出图像文件夹不存在，创建它\n",
    "    if not os.path.exists(output_mask_folder):\n",
    "        os.makedirs(output_mask_folder)  # 如果输出掩码文件夹不存在，创建它\n",
    "\n",
    "    image_files = os.listdir(input_image_folder)  # 获取输入图像文件夹中的所有文件名\n",
    "\n",
    "    for image_file in image_files:\n",
    "        if image_file.endswith('.jpg'):\n",
    "            image_file = os.path.join(image_file[:-4] + '.png')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        image_path = os.path.join(input_image_folder, image_file)  # 构建图像文件的完整路径\n",
    "        mask_path = os.path.join(input_mask_folder, image_file)  # 构建对应掩码文件的完整路径\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"掩码文件 {mask_path} 不存在，跳过。\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(image_path)  # 读取图像\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # 读取掩码（灰度图像）\n",
    "        \n",
    "        image_aug, mask_aug = augment_image(image, mask)  # 对图像和掩码进行数据增强\n",
    "\n",
    "        # 构建增强后图像和掩码的保存路径\n",
    "        output_image_path = os.path.join(output_image_folder, image_file)\n",
    "        output_mask_path = os.path.join(output_mask_folder, image_file)\n",
    "        \n",
    "        cv2.imwrite(output_image_path, image_aug)  # 保存增强后的图像\n",
    "        cv2.imwrite(output_mask_path, mask_aug)  # 保存增强后的掩码\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    Dataset_Path = r\"F:\\work\\dataset\\rebar2D\\train\\label\"  # 数据集路径\n",
    "    img_path = r\"F:\\work\\dataset\\rebar2D\\train\\img\"\n",
    "    labelme_json_path = r\"F:\\work\\dataset\\rebar2D\\train\\label\"\n",
    "    mask_path=r\"F:\\work\\dataset\\rebar2D\\train\\mask\" # 掩码图像文件夹路径\n",
    "    \n",
    "    input_image_folder = img_path  # 输入图像文件夹路径\n",
    "    input_mask_folder = mask_path  # 输入掩码文件夹路径\n",
    "    output_image_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img1\"  # 输出图像文件夹路径\n",
    "    output_mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask1\"  # 输出掩码文件夹路径\n",
    "\n",
    "    process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder)  # 处理文件夹中的所有图像和掩码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e596c8df17b5b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T03:08:14.170296Z",
     "start_time": "2024-06-30T03:05:29.754282Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 83\u001B[0m\n\u001B[0;32m     78\u001B[0m output_mask_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mwork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mrebar2D\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmask1\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# 输出掩码文件夹路径\u001B[39;00m\n\u001B[0;32m     81\u001B[0m label_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# or \"json\"\u001B[39;00m\n\u001B[1;32m---> 83\u001B[0m process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format)\n",
      "Cell \u001B[1;32mIn[8], line 61\u001B[0m, in \u001B[0;36mprocess_folder\u001B[1;34m(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format)\u001B[0m\n\u001B[0;32m     58\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(image_path)\n\u001B[0;32m     59\u001B[0m mask \u001B[38;5;241m=\u001B[39m read_mask(mask_path, label_format)\n\u001B[1;32m---> 61\u001B[0m image_aug, mask_aug \u001B[38;5;241m=\u001B[39m augment_image(image, mask)\n\u001B[0;32m     63\u001B[0m output_image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_image_folder, image_file)\n\u001B[0;32m     64\u001B[0m output_mask_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_mask_folder, mask_file)\n",
      "Cell \u001B[1;32mIn[8], line 20\u001B[0m, in \u001B[0;36maugment_image\u001B[1;34m(image, mask)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maugment_image\u001B[39m(image, mask):\n\u001B[0;32m      8\u001B[0m     transform \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      9\u001B[0m         A\u001B[38;5;241m.\u001B[39mHorizontalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),\n\u001B[0;32m     10\u001B[0m         A\u001B[38;5;241m.\u001B[39mVerticalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[38;5;66;03m# A.RandomCrop(height=256, width=256, p=1.0)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     ])\n\u001B[1;32m---> 20\u001B[0m     augmented \u001B[38;5;241m=\u001B[39m transform(image\u001B[38;5;241m=\u001B[39mimage, mask\u001B[38;5;241m=\u001B[39mmask)\n\u001B[0;32m     21\u001B[0m     image_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     22\u001B[0m     mask_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:272\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(data)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m--> 272\u001B[0m     data \u001B[38;5;241m=\u001B[39m t(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_each_transform:\n\u001B[0;32m    275\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_data_post_transform(data)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:112\u001B[0m, in \u001B[0;36mBasicTransform.__call__\u001B[1;34m(self, force_apply, *args, **kwargs)\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeterministic:\n\u001B[0;32m    111\u001B[0m         kwargs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_key][\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m)] \u001B[38;5;241m=\u001B[39m deepcopy(params)\n\u001B[1;32m--> 112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_with_params(params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m kwargs\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:123\u001B[0m, in \u001B[0;36mBasicTransform.apply_with_params\u001B[1;34m(self, params, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key2func \u001B[38;5;129;01mand\u001B[39;00m arg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     target_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key2func[key]\n\u001B[1;32m--> 123\u001B[0m     res[key] \u001B[38;5;241m=\u001B[39m target_function(arg, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    125\u001B[0m     res[key] \u001B[38;5;241m=\u001B[39m arg\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\augmentations\\geometric\\transforms.py:150\u001B[0m, in \u001B[0;36mElasticTransform.apply\u001B[1;34m(self, img, random_seed, interpolation, **params)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    145\u001B[0m     img: np\u001B[38;5;241m.\u001B[39mndarray,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams: Any,\n\u001B[0;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fgeometric\u001B[38;5;241m.\u001B[39melastic_transform(\n\u001B[0;32m    151\u001B[0m         img,\n\u001B[0;32m    152\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha,\n\u001B[0;32m    153\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigma,\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha_affine,\n\u001B[0;32m    155\u001B[0m         interpolation,\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mborder_mode,\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue,\n\u001B[0;32m    158\u001B[0m         np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mRandomState(random_seed),\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapproximate,\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msame_dxdy,\n\u001B[0;32m    161\u001B[0m     )\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albucore\\utils.py:113\u001B[0m, in \u001B[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001B[1;34m(img, *args, **kwargs)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_function\u001B[39m(img: np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m    112\u001B[0m     shape \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m--> 113\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(img, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;241m==\u001B[39m NUM_MULTI_CHANNEL_DIMENSIONS \u001B[38;5;129;01mand\u001B[39;00m shape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m result\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m MONO_CHANNEL_DIMENSIONS:\n\u001B[0;32m    115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mexpand_dims(result, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py:404\u001B[0m, in \u001B[0;36melastic_transform\u001B[1;34m(img, alpha, sigma, alpha_affine, interpolation, border_mode, value, random_state, approximate, same_dxdy)\u001B[0m\n\u001B[0;32m    401\u001B[0m         dy \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m alpha\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    403\u001B[0m     dx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32(\n\u001B[1;32m--> 404\u001B[0m         gaussian_filter((random_utils\u001B[38;5;241m.\u001B[39mrand(height, width, random_state\u001B[38;5;241m=\u001B[39mrandom_state) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m), sigma) \u001B[38;5;241m*\u001B[39m alpha,\n\u001B[0;32m    405\u001B[0m     )\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m same_dxdy:\n\u001B[0;32m    407\u001B[0m         \u001B[38;5;66;03m# Speed up\u001B[39;00m\n\u001B[0;32m    408\u001B[0m         dy \u001B[38;5;241m=\u001B[39m dx\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:385\u001B[0m, in \u001B[0;36mgaussian_filter\u001B[1;34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001B[0m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(axes) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m axis, sigma, order, mode, radius \u001B[38;5;129;01min\u001B[39;00m axes:\n\u001B[1;32m--> 385\u001B[0m         gaussian_filter1d(\u001B[38;5;28minput\u001B[39m, sigma, axis, order, output,\n\u001B[0;32m    386\u001B[0m                           mode, cval, truncate, radius\u001B[38;5;241m=\u001B[39mradius)\n\u001B[0;32m    387\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:283\u001B[0m, in \u001B[0;36mgaussian_filter1d\u001B[1;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001B[0m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001B[39;00m\n\u001B[0;32m    282\u001B[0m weights \u001B[38;5;241m=\u001B[39m _gaussian_kernel1d(sigma, order, lw)[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 283\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m correlate1d(\u001B[38;5;28minput\u001B[39m, weights, axis, output, mode, cval, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:140\u001B[0m, in \u001B[0;36mcorrelate1d\u001B[1;34m(input, weights, axis, output, mode, cval, origin)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInvalid origin; origin must satisfy \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    137\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-(len(weights) // 2) <= origin <= \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    138\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(len(weights)-1) // 2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    139\u001B[0m mode \u001B[38;5;241m=\u001B[39m _ni_support\u001B[38;5;241m.\u001B[39m_extend_mode_to_code(mode)\n\u001B[1;32m--> 140\u001B[0m _nd_image\u001B[38;5;241m.\u001B[39mcorrelate1d(\u001B[38;5;28minput\u001B[39m, weights, axis, output, mode, cval,\n\u001B[0;32m    141\u001B[0m                       origin)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import os\n",
    "import json\n",
    "\n",
    "def augment_image(image, mask):\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.ElasticTransform(p=0.2),\n",
    "        A.GridDistortion(p=0.2),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.2),\n",
    "        # A.RandomCrop(height=256, width=256, p=1.0)\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image, mask=mask)\n",
    "    image_aug = augmented['image']\n",
    "    mask_aug = augmented['mask']\n",
    "    \n",
    "    return image_aug, mask_aug\n",
    "\n",
    "def read_mask(mask_path, label_format):\n",
    "    if label_format == \"mask\":\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "    elif label_format == \"json\":\n",
    "        with open(mask_path, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "            mask = np.zeros((annotations['imageHeight'], annotations['imageWidth']), dtype=np.uint8)\n",
    "            for shape in annotations['shapes']:\n",
    "                points = np.array(shape['points'], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points], color=(255))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported label format. Use 'mask' or 'json'.\")\n",
    "    return mask\n",
    "\n",
    "def process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format=\"mask\"):\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "    if not os.path.exists(output_mask_folder):\n",
    "        os.makedirs(output_mask_folder)\n",
    "\n",
    "    image_files = os.listdir(input_image_folder)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_image_folder, image_file)\n",
    "        \n",
    "        mask_file = image_file.replace('.jpg', '.png') if label_format == \"mask\" else image_file.replace('.jpg', '.json')\n",
    "        mask_path = os.path.join(input_mask_folder, mask_file)\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Label file {mask_path} does not exist, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        mask = read_mask(mask_path, label_format)\n",
    "        \n",
    "        image_aug, mask_aug = augment_image(image, mask)\n",
    "        \n",
    "        output_image_path = os.path.join(output_image_folder, image_file)\n",
    "        output_mask_path = os.path.join(output_mask_folder, mask_file)\n",
    "        \n",
    "        cv2.imwrite(output_image_path, image_aug)\n",
    "        cv2.imwrite(output_mask_path, mask_aug)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Dataset_Path = r\"F:\\work\\dataset\\rebar2D\\train\\label\"  # 数据集路径\n",
    "    img_path = r\"F:\\work\\dataset\\rebar2D\\train\\img\"\n",
    "    labelme_json_path = r\"F:\\work\\dataset\\rebar2D\\train\\label\"\n",
    "    mask_path=r\"F:\\work\\dataset\\rebar2D\\train\\mask\" # 掩码图像文件夹路径\n",
    "    \n",
    "    input_image_folder = img_path  # 输入图像文件夹路径\n",
    "    input_mask_folder = mask_path  # 输入掩码文件夹路径\n",
    "    output_image_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img1\"  # 输出图像文件夹路径\n",
    "    output_mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask1\"  # 输出掩码文件夹路径\n",
    "    \n",
    "\n",
    "    label_format = \"mask\"  # or \"json\"\n",
    "    \n",
    "    process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b464c350dc900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa6ed4bcc4f48ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T05:00:41.459994Z",
     "start_time": "2024-06-30T04:58:48.556789Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 119\u001B[0m\n\u001B[0;32m    116\u001B[0m label_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# 标签格式，可选\"mask\"或\"json\"\u001B[39;00m\n\u001B[0;32m    117\u001B[0m n_augmentations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m  \u001B[38;5;66;03m# 每张图像增强的数量\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations)\n",
      "Cell \u001B[1;32mIn[15], line 87\u001B[0m, in \u001B[0;36mprocess_folder\u001B[1;34m(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations)\u001B[0m\n\u001B[0;32m     84\u001B[0m mask_file \u001B[38;5;241m=\u001B[39m image_file\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m label_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m image_file\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     85\u001B[0m mask_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(input_mask_folder, mask_file)  \u001B[38;5;66;03m# 构建掩码文件路径\u001B[39;00m\n\u001B[1;32m---> 87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(mask_path):\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLabel file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmask_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist, skipping.\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# 如果掩码文件不存在，跳过该文件\u001B[39;00m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1065\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mF:\\install\\PyCharm 2024.1.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1187\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1184\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1187\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)\n",
      "File \u001B[1;32mF:\\install\\PyCharm 2024.1.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1202\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1199\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1201\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1202\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1206\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import os\n",
    "import json\n",
    "\n",
    "def pca_color_augmentation(image, alpha_std=0.1):\n",
    "    \"\"\" 使用PCA对图像进行颜色增强 \"\"\"\n",
    "    orig_img = image.astype(float)\n",
    "    img_rs = orig_img.reshape(-1, 3)\n",
    "    img_mean = np.mean(img_rs, axis=0)\n",
    "    img_std = np.std(img_rs, axis=0)\n",
    "    img_rs = (img_rs - img_mean) / img_std\n",
    "\n",
    "    cov = np.cov(img_rs, rowvar=False)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\n",
    "    noise = np.random.normal(0, alpha_std, 3)\n",
    "    noise = eigvecs @ (eigvals ** 0.5) * noise\n",
    "    noise = (noise * img_std) + img_mean\n",
    "\n",
    "    aug_img = orig_img + noise\n",
    "    aug_img = np.clip(aug_img, 0, 255).astype(np.uint8)\n",
    "    return aug_img\n",
    "\n",
    "def augment_image(image, mask, n_augmentations=1):\n",
    "    # 定义数据增强的变换序列\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),  # 水平翻转，概率为50%\n",
    "        A.VerticalFlip(p=0.5),    # 垂直翻转，概率为50%\n",
    "        A.RandomRotate90(p=0.5),  # 随机旋转90度，概率为50%\n",
    "        # A.Transpose(p=0.5),       # 转置操作（交换x和y轴），概率为50%\n",
    "        A.RandomBrightnessContrast(p=0.2),  # 随机调整亮度和对比度，概率为20%\n",
    "        A.ElasticTransform(p=0.2),  # 弹性变换，概率为20%\n",
    "        A.GridDistortion(p=0.2),    # 网格扭曲，概率为20%\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.2),  # 平移、缩放和旋转，概率为20%\n",
    "        # A.RandomCrop(height=256, width=256, p=1.0)  # 随机裁剪到256x256大小\n",
    "    ])\n",
    "    \n",
    "    augmented_images = []\n",
    "    augmented_masks = []\n",
    "    \n",
    "    for _ in range(n_augmentations):\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        image_aug = augmented['image']\n",
    "        mask_aug = augmented['mask']\n",
    "        \n",
    "        # 应用PCA颜色增强\n",
    "        image_aug = pca_color_augmentation(image_aug)\n",
    "        \n",
    "        augmented_images.append(image_aug)\n",
    "        augmented_masks.append(mask_aug)\n",
    "    \n",
    "    return augmented_images, augmented_masks  # 返回增强后的图像和掩码\n",
    "\n",
    "def read_mask(mask_path, label_format):\n",
    "    # 读取掩码文件，根据标签格式选择不同的方法\n",
    "    if label_format == \"mask\":\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)  # 读取PNG格式掩码\n",
    "    elif label_format == \"json\":\n",
    "        with open(mask_path, 'r') as f:\n",
    "            annotations = json.load(f)  # 读取JSON文件\n",
    "            mask = np.zeros((annotations['imageHeight'], annotations['imageWidth']), dtype=np.uint8)  # 创建空白掩码\n",
    "            for shape in annotations['shapes']:\n",
    "                points = np.array(shape['points'], dtype=np.int32)  # 将形状的点转换为数组\n",
    "                cv2.fillPoly(mask, [points], color=(255))  # 用白色填充多边形\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported label format. Use 'mask' or 'json'.\")  # 抛出异常\n",
    "    return mask  # 返回生成的掩码\n",
    "\n",
    "def process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format=\"mask\", n_augmentations=5):\n",
    "    # 检查输出文件夹是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "    if not os.path.exists(output_mask_folder):\n",
    "        os.makedirs(output_mask_folder)\n",
    "\n",
    "    image_files = os.listdir(input_image_folder)  # 获取输入图像文件列表\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_image_folder, image_file)  # 构建图像文件路径\n",
    "        \n",
    "        # 根据标签格式选择相应的掩码文件名\n",
    "        mask_file = image_file.replace('.jpg', '.png') if label_format == \"mask\" else image_file.replace('.jpg', '.json')\n",
    "        mask_path = os.path.join(input_mask_folder, mask_file)  # 构建掩码文件路径\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Label file {mask_path} does not exist, skipping.\")  # 如果掩码文件不存在，跳过该文件\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(image_path)  # 读取图像文件\n",
    "        mask = read_mask(mask_path, label_format)  # 读取掩码文件\n",
    "        \n",
    "        augmented_images, augmented_masks = augment_image(image, mask, n_augmentations)  # 对图像和掩码进行数据增强\n",
    "        \n",
    "        for i, (image_aug, mask_aug) in enumerate(zip(augmented_images, augmented_masks)):\n",
    "            output_image_path = os.path.join(output_image_folder, f\"{os.path.splitext(image_file)[0]}_aug_{i}.jpg\")  # 输出图像文件路径\n",
    "            output_mask_path = os.path.join(output_mask_folder, f\"{os.path.splitext(mask_file)[0]}_aug_{i}.png\")  # 输出掩码文件路径\n",
    "            \n",
    "            cv2.imwrite(output_image_path, image_aug)  # 保存增强后的图像\n",
    "            cv2.imwrite(output_mask_path, mask_aug)  # 保存增强后的掩码\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Dataset_Path = r\"F:\\work\\dataset\\rebar2D\\train\\label\"  # 数据集路径\n",
    "    img_path = r\"F:\\work\\dataset\\rebar2D\\train\\img\"\n",
    "    labelme_json_path = r\"F:\\work\\dataset\\rebar2D\\train\\label\"\n",
    "    mask_path=r\"F:\\work\\dataset\\rebar2D\\train\\mask\" # 掩码图像文件夹路径\n",
    "    \n",
    "    # input_image_folder = img_path  # 输入图像文件夹路径\n",
    "    input_image_folder = r\"H:\\data\\rebar2D\\train\\img\"\n",
    "    input_mask_folder = mask_path  # 输入掩码文件夹路径\n",
    "    output_image_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img1\"  # 输出图像文件夹路径\n",
    "    output_mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask1\"  # 输出掩码文件夹路径 \n",
    "\n",
    "    label_format = \"mask\"  # 标签格式，可选\"mask\"或\"json\"\n",
    "    n_augmentations = 5  # 每张图像增强的数量\n",
    "    \n",
    "    process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations)  # 处理文件夹中的文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "487d85331403e12b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:16:24.497880Z",
     "start_time": "2024-06-30T06:16:02.183884Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 122\u001B[0m\n\u001B[0;32m    118\u001B[0m label_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# 标签格式，可选\"mask\"或\"json\"\u001B[39;00m\n\u001B[0;32m    120\u001B[0m n_augmentations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m  \u001B[38;5;66;03m# 每张图像增强的数量\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations)\n",
      "Cell \u001B[1;32mIn[17], line 101\u001B[0m, in \u001B[0;36mprocess_folder\u001B[1;34m(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations)\u001B[0m\n\u001B[0;32m     98\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(image_path)  \u001B[38;5;66;03m# 读取图像文件\u001B[39;00m\n\u001B[0;32m     99\u001B[0m mask \u001B[38;5;241m=\u001B[39m read_mask(mask_path, label_format)  \u001B[38;5;66;03m# 读取掩码文件\u001B[39;00m\n\u001B[1;32m--> 101\u001B[0m augmented_images, augmented_masks \u001B[38;5;241m=\u001B[39m augment_image(image, mask, n_augmentations)  \u001B[38;5;66;03m# 对图像和掩码进行数据增强\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (image_aug, mask_aug) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(augmented_images, augmented_masks)):\n\u001B[0;32m    104\u001B[0m     output_image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_image_folder, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(image_file)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_aug_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# 输出图像文件路径\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[17], line 44\u001B[0m, in \u001B[0;36maugment_image\u001B[1;34m(image, mask, n_augmentations)\u001B[0m\n\u001B[0;32m     41\u001B[0m augmented_masks \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# 存储增强后的掩码\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_augmentations):\n\u001B[1;32m---> 44\u001B[0m     augmented \u001B[38;5;241m=\u001B[39m transform(image\u001B[38;5;241m=\u001B[39mimage, mask\u001B[38;5;241m=\u001B[39mmask)  \u001B[38;5;66;03m# 对图像和掩码进行增强\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     image_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 获取增强后的图像\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     mask_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 获取增强后的掩码\u001B[39;00m\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:272\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(data)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m--> 272\u001B[0m     data \u001B[38;5;241m=\u001B[39m t(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_each_transform:\n\u001B[0;32m    275\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_data_post_transform(data)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:112\u001B[0m, in \u001B[0;36mBasicTransform.__call__\u001B[1;34m(self, force_apply, *args, **kwargs)\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeterministic:\n\u001B[0;32m    111\u001B[0m         kwargs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_key][\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m)] \u001B[38;5;241m=\u001B[39m deepcopy(params)\n\u001B[1;32m--> 112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_with_params(params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m kwargs\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:123\u001B[0m, in \u001B[0;36mBasicTransform.apply_with_params\u001B[1;34m(self, params, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key2func \u001B[38;5;129;01mand\u001B[39;00m arg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     target_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key2func[key]\n\u001B[1;32m--> 123\u001B[0m     res[key] \u001B[38;5;241m=\u001B[39m target_function(arg, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    125\u001B[0m     res[key] \u001B[38;5;241m=\u001B[39m arg\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\augmentations\\geometric\\transforms.py:150\u001B[0m, in \u001B[0;36mElasticTransform.apply\u001B[1;34m(self, img, random_seed, interpolation, **params)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    145\u001B[0m     img: np\u001B[38;5;241m.\u001B[39mndarray,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams: Any,\n\u001B[0;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fgeometric\u001B[38;5;241m.\u001B[39melastic_transform(\n\u001B[0;32m    151\u001B[0m         img,\n\u001B[0;32m    152\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha,\n\u001B[0;32m    153\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigma,\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha_affine,\n\u001B[0;32m    155\u001B[0m         interpolation,\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mborder_mode,\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue,\n\u001B[0;32m    158\u001B[0m         np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mRandomState(random_seed),\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapproximate,\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msame_dxdy,\n\u001B[0;32m    161\u001B[0m     )\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albucore\\utils.py:113\u001B[0m, in \u001B[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001B[1;34m(img, *args, **kwargs)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_function\u001B[39m(img: np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m    112\u001B[0m     shape \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m--> 113\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(img, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;241m==\u001B[39m NUM_MULTI_CHANNEL_DIMENSIONS \u001B[38;5;129;01mand\u001B[39;00m shape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m result\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m MONO_CHANNEL_DIMENSIONS:\n\u001B[0;32m    115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mexpand_dims(result, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py:404\u001B[0m, in \u001B[0;36melastic_transform\u001B[1;34m(img, alpha, sigma, alpha_affine, interpolation, border_mode, value, random_state, approximate, same_dxdy)\u001B[0m\n\u001B[0;32m    401\u001B[0m         dy \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m alpha\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    403\u001B[0m     dx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32(\n\u001B[1;32m--> 404\u001B[0m         gaussian_filter((random_utils\u001B[38;5;241m.\u001B[39mrand(height, width, random_state\u001B[38;5;241m=\u001B[39mrandom_state) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m), sigma) \u001B[38;5;241m*\u001B[39m alpha,\n\u001B[0;32m    405\u001B[0m     )\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m same_dxdy:\n\u001B[0;32m    407\u001B[0m         \u001B[38;5;66;03m# Speed up\u001B[39;00m\n\u001B[0;32m    408\u001B[0m         dy \u001B[38;5;241m=\u001B[39m dx\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:385\u001B[0m, in \u001B[0;36mgaussian_filter\u001B[1;34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001B[0m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(axes) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m axis, sigma, order, mode, radius \u001B[38;5;129;01min\u001B[39;00m axes:\n\u001B[1;32m--> 385\u001B[0m         gaussian_filter1d(\u001B[38;5;28minput\u001B[39m, sigma, axis, order, output,\n\u001B[0;32m    386\u001B[0m                           mode, cval, truncate, radius\u001B[38;5;241m=\u001B[39mradius)\n\u001B[0;32m    387\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:283\u001B[0m, in \u001B[0;36mgaussian_filter1d\u001B[1;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001B[0m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001B[39;00m\n\u001B[0;32m    282\u001B[0m weights \u001B[38;5;241m=\u001B[39m _gaussian_kernel1d(sigma, order, lw)[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 283\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m correlate1d(\u001B[38;5;28minput\u001B[39m, weights, axis, output, mode, cval, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:140\u001B[0m, in \u001B[0;36mcorrelate1d\u001B[1;34m(input, weights, axis, output, mode, cval, origin)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInvalid origin; origin must satisfy \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    137\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-(len(weights) // 2) <= origin <= \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    138\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(len(weights)-1) // 2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    139\u001B[0m mode \u001B[38;5;241m=\u001B[39m _ni_support\u001B[38;5;241m.\u001B[39m_extend_mode_to_code(mode)\n\u001B[1;32m--> 140\u001B[0m _nd_image\u001B[38;5;241m.\u001B[39mcorrelate1d(\u001B[38;5;28minput\u001B[39m, weights, axis, output, mode, cval,\n\u001B[0;32m    141\u001B[0m                       origin)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2  # 导入OpenCV库，用于图像处理\n",
    "import numpy as np  # 导入NumPy库，用于数值计算\n",
    "import albumentations as A  # 导入Albumentations库，用于图像增强\n",
    "import os  # 导入OS库，用于文件和目录操作\n",
    "import json  # 导入JSON库，用于处理JSON格式的数据\n",
    "\n",
    "def pca_color_augmentation(image, alpha_std=0.1):\n",
    "    \"\"\" 使用PCA对图像进行颜色增强 \"\"\"\n",
    "    orig_img = image.astype(float)  # 将图像转换为浮点数类型\n",
    "    img_rs = orig_img.reshape(-1, 3)  # 将图像重塑为二维数组\n",
    "    img_mean = np.mean(img_rs, axis=0)  # 计算每个通道的均值\n",
    "    img_std = np.std(img_rs, axis=0)  # 计算每个通道的标准差\n",
    "    img_rs = (img_rs - img_mean) / img_std  # 对图像进行标准化处理\n",
    "\n",
    "    cov = np.cov(img_rs, rowvar=False)  # 计算协方差矩阵\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)  # 计算特征值和特征向量\n",
    "\n",
    "    noise = np.random.normal(0, alpha_std, 3)  # 生成正态分布的噪声\n",
    "    noise = eigvecs @ (eigvals ** 0.5) * noise  # 应用PCA变换\n",
    "    noise = (noise * img_std) + img_mean  # 反标准化处理\n",
    "\n",
    "    aug_img = orig_img + noise  # 将噪声加到原图像上\n",
    "    aug_img = np.clip(aug_img, 0, 255).astype(np.uint8)  # 裁剪值并转换为8位无符号整数\n",
    "    return aug_img  # 返回增强后的图像\n",
    "\n",
    "def augment_image(image, mask, n_augmentations=1):\n",
    "    # 定义数据增强的变换序列\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),  # 水平翻转，概率为50%\n",
    "        A.VerticalFlip(p=0.5),    # 垂直翻转，概率为50%\n",
    "        A.RandomRotate90(p=0.5),  # 随机旋转90度，概率为50%\n",
    "        # A.Transpose(p=0.5),       # 转置操作（交换x和y轴），概率为50%\n",
    "        A.RandomBrightnessContrast(p=0.2),  # 随机调整亮度和对比度，概率为20%\n",
    "        A.ElasticTransform(p=0.2),  # 弹性变换，概率为20%\n",
    "        A.GridDistortion(p=0.2),    # 网格扭曲，概率为20%\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.2),  # 平移、缩放和旋转，概率为20%\n",
    "        # A.RandomCrop(height=256, width=256, p=1.0)  # 随机裁剪到256x256大小，概率为100%\n",
    "    ])\n",
    "    \n",
    "    augmented_images = []  # 存储增强后的图像\n",
    "    augmented_masks = []  # 存储增强后的掩码\n",
    "    \n",
    "    for _ in range(n_augmentations):\n",
    "        augmented = transform(image=image, mask=mask)  # 对图像和掩码进行增强\n",
    "        image_aug = augmented['image']  # 获取增强后的图像\n",
    "        mask_aug = augmented['mask']  # 获取增强后的掩码\n",
    "        \n",
    "        # 应用PCA颜色增强\n",
    "        image_aug = pca_color_augmentation(image_aug)\n",
    "        \n",
    "        augmented_images.append(image_aug)  # 添加到增强图像列表\n",
    "        augmented_masks.append(mask_aug)  # 添加到增强掩码列表\n",
    "    \n",
    "    return augmented_images, augmented_masks  # 返回增强后的图像和掩码\n",
    "\n",
    "def read_mask(mask_path, label_format):\n",
    "    # 读取掩码文件，根据标签格式选择不同的方法\n",
    "    if label_format == \"mask\":\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)  # 读取PNG格式掩码\n",
    "    elif label_format == \"json\":\n",
    "        with open(mask_path, 'r') as f:\n",
    "            annotations = json.load(f)  # 读取JSON文件\n",
    "            mask = np.zeros((annotations['imageHeight'], annotations['imageWidth']), dtype=np.uint8)  # 创建空白掩码\n",
    "            for shape in annotations['shapes']:\n",
    "                points = np.array(shape['points'], dtype=np.int32)  # 将形状的点转换为数组\n",
    "                cv2.fillPoly(mask, [points], color=(255))  # 用白色填充多边形\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported label format. Use 'mask' or 'json'.\")  # 抛出异常\n",
    "    return mask  # 返回生成的掩码\n",
    "\n",
    "def process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format=\"mask\", n_augmentations=5):\n",
    "    # 检查输出文件夹是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "    if not os.path.exists(output_mask_folder):\n",
    "        os.makedirs(output_mask_folder)\n",
    "\n",
    "    image_files = os.listdir(input_image_folder)  # 获取输入图像文件列表\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_image_folder, image_file)  # 构建图像文件路径\n",
    "        \n",
    "        # 根据标签格式选择相应的掩码文件名\n",
    "        if image_path.endswith('.jpg'):\n",
    "            mask_file = image_file.replace('.jpg', '.png') if label_format == \"mask\" else image_file.replace(\n",
    "            '.jpg','.json')\n",
    "        elif image_path.endswith('.bmp'):\n",
    "            mask_file = image_file.replace('.bmp', '.png') if label_format == \"mask\" else image_file.replace(\n",
    "                '.bmp','.json')\n",
    "        else:\n",
    "            print(f\"Unsupported image format for {image_path}, skipping.\")\n",
    "        mask_path = os.path.join(input_mask_folder, mask_file)  # 构建掩码文件路径\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Label file {mask_path} does not exist, skipping.\")  # 如果掩码文件不存在，跳过该文件\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(image_path)  # 读取图像文件\n",
    "        mask = read_mask(mask_path, label_format)  # 读取掩码文件\n",
    "        \n",
    "        augmented_images, augmented_masks = augment_image(image, mask, n_augmentations)  # 对图像和掩码进行数据增强\n",
    "        \n",
    "        for i, (image_aug, mask_aug) in enumerate(zip(augmented_images, augmented_masks)):\n",
    "            output_image_path = os.path.join(output_image_folder, f\"{os.path.splitext(image_file)[0]}_aug_{i}.jpg\")  # 输出图像文件路径\n",
    "            output_mask_path = os.path.join(output_mask_folder, f\"{os.path.splitext(mask_file)[0]}_aug_{i}.png\")  # 输出掩码文件路径\n",
    "            \n",
    "            cv2.imwrite(output_image_path, image_aug)  # 保存增强后的图像\n",
    "            cv2.imwrite(output_mask_path, mask_aug)  # 保存增强后的掩码\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # input_image_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img\"  # 输入图像文件夹路径\n",
    "    input_image_folder = r\"H:\\data\\rebar2D\\train\\img\"\n",
    "    input_mask_folder =r\"F:\\work\\dataset\\rebar2D\\train\\mask\"  # 输入掩码文件夹路径\n",
    "    output_image_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img1\"  # 输出图像文件夹路径\n",
    "    output_mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask1\"  # 输出掩码文件夹路径\n",
    "    \n",
    "    label_format = \"mask\"  # 标签格式，可选\"mask\"或\"json\"\n",
    "    \n",
    "    n_augmentations = 5  # 每张图像增强的数量\n",
    "    \n",
    "    process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations)  # 处理文件夹中的文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae886018b3586e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:25:14.607584Z",
     "start_time": "2024-06-30T06:25:14.448259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "image = cv2.imread(r'F:\\work\\python\\clone\\dataset\\rebar2d\\images\\Image_20240622152006003.jpg')\n",
    "\n",
    "# 将图像从BGR颜色空间转换为HSV颜色空间\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 定义棕褐色的HSV范围\n",
    "brown_lower = np.array([10, 50, 20])\n",
    "brown_upper = np.array([30, 255, 200])\n",
    "\n",
    "# 创建掩膜，仅保留棕褐色区域\n",
    "brown_mask = cv2.inRange(hsv_image, brown_lower, brown_upper)\n",
    "\n",
    "# 对原始图像应用掩膜\n",
    "enhanced_image = cv2.bitwise_and(image, image, mask=brown_mask)\n",
    "\n",
    "# 增强棕褐色区域的亮度和饱和度\n",
    "enhanced_hsv_image = hsv_image.copy()\n",
    "enhanced_hsv_image[..., 2] = cv2.add(enhanced_hsv_image[..., 2], 50)  # 调整亮度\n",
    "enhanced_hsv_image[..., 1] = cv2.add(enhanced_hsv_image[..., 1], 50)  # 调整饱和度\n",
    "\n",
    "# 将调整后的HSV图像转换回BGR颜色空间\n",
    "enhanced_bgr_image = cv2.cvtColor(enhanced_hsv_image, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "# 将增强后的棕褐色区域与原始图像合并\n",
    "final_image = cv2.addWeighted(image, 0.7, enhanced_bgr_image, 0.3, 0)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imwrite(r\"F:\\work\\dataset\\rebar2D\\train\\TEMP\\11.jpg\", final_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f76a0849abe29ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:35:17.709575Z",
     "start_time": "2024-06-30T06:35:14.587707Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mask must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 129\u001B[0m\n\u001B[0;32m    126\u001B[0m n_augmentations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m  \u001B[38;5;66;03m# 每张图像增强的数量\u001B[39;00m\n\u001B[0;32m    127\u001B[0m color_augmentation \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbrownify\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# 颜色增强方式，可选\"pca\"或\"brownify\"\u001B[39;00m\n\u001B[1;32m--> 129\u001B[0m process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations, color_augmentation)\n",
      "Cell \u001B[1;32mIn[25], line 111\u001B[0m, in \u001B[0;36mprocess_folder\u001B[1;34m(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations, color_augmentation)\u001B[0m\n\u001B[0;32m    108\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(image_path)  \u001B[38;5;66;03m# 读取图像文件\u001B[39;00m\n\u001B[0;32m    109\u001B[0m mask \u001B[38;5;241m=\u001B[39m read_mask(mask_path, label_format)  \u001B[38;5;66;03m# 读取掩码文件\u001B[39;00m\n\u001B[1;32m--> 111\u001B[0m augmented_images, augmented_masks \u001B[38;5;241m=\u001B[39m augment_image(image, mask, n_augmentations, color_augmentation)  \u001B[38;5;66;03m# 对图像和掩码进行数据增强\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (image_aug, mask_aug) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(augmented_images, augmented_masks)):\n\u001B[0;32m    114\u001B[0m     output_image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_image_folder, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(image_file)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_aug_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# 输出图像文件路径\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[25], line 52\u001B[0m, in \u001B[0;36maugment_image\u001B[1;34m(image, mask, n_augmentations, color_augmentation)\u001B[0m\n\u001B[0;32m     49\u001B[0m augmented_masks \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# 存储增强后的掩码\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_augmentations):\n\u001B[1;32m---> 52\u001B[0m     augmented \u001B[38;5;241m=\u001B[39m transform(image\u001B[38;5;241m=\u001B[39mimage, mask\u001B[38;5;241m=\u001B[39mmask)  \u001B[38;5;66;03m# 对图像和掩码进行增强\u001B[39;00m\n\u001B[0;32m     53\u001B[0m     image_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 获取增强后的图像\u001B[39;00m\n\u001B[0;32m     54\u001B[0m     mask_aug \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 获取增强后的掩码\u001B[39;00m\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:269\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m need_to_run:\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n\u001B[1;32m--> 269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(data)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m    272\u001B[0m     data \u001B[38;5;241m=\u001B[39m t(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:297\u001B[0m, in \u001B[0;36mCompose.preprocess\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_check_args:\n\u001B[1;32m--> 297\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_args(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    299\u001B[0m         p\u001B[38;5;241m.\u001B[39mensure_data_valid(data)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\albumentations\\core\\composition.py:362\u001B[0m, in \u001B[0;36mCompose._check_args\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m internal_data_name \u001B[38;5;129;01min\u001B[39;00m checked_single:\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m--> 362\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be numpy array type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    363\u001B[0m     shapes\u001B[38;5;241m.\u001B[39mappend(data\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m internal_data_name \u001B[38;5;129;01min\u001B[39;00m checked_multi \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data):\n",
      "\u001B[1;31mTypeError\u001B[0m: mask must be numpy array type"
     ]
    }
   ],
   "source": [
    "import cv2  # 导入OpenCV库，用于图像处理\n",
    "import numpy as np  # 导入NumPy库，用于数值计算\n",
    "import albumentations as A  # 导入Albumentations库，用于图像增强\n",
    "import os  # 导入OS库，用于文件和目录操作\n",
    "import json  # 导入JSON库，用于处理JSON格式的数据\n",
    "\n",
    "def pca_color_augmentation(image, alpha_std=0.1):\n",
    "    \"\"\" 使用PCA对图像进行颜色增强 \"\"\"\n",
    "    orig_img = image.astype(float)  # 将图像转换为浮点数类型\n",
    "    img_rs = orig_img.reshape(-1, 3)  # 将图像重塑为二维数组\n",
    "    img_mean = np.mean(img_rs, axis=0)  # 计算每个通道的均值\n",
    "    img_std = np.std(img_rs, axis=0)  # 计算每个通道的标准差\n",
    "    img_rs = (img_rs - img_mean) / img_std  # 对图像进行标准化处理\n",
    "\n",
    "    cov = np.cov(img_rs, rowvar=False)  # 计算协方差矩阵\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)  # 计算特征值和特征向量\n",
    "\n",
    "    noise = np.random.normal(0, alpha_std, 3)  # 生成正态分布的噪声\n",
    "    noise = eigvecs @ (eigvals ** 0.5) * noise  # 应用PCA变换\n",
    "    noise = (noise * img_std) + img_mean  # 反标准化处理\n",
    "\n",
    "    aug_img = orig_img + noise  # 将噪声加到原图像上\n",
    "    aug_img = np.clip(aug_img, 0, 255).astype(np.uint8)  # 裁剪值并转换为8位无符号整数\n",
    "    return aug_img  # 返回增强后的图像\n",
    "\n",
    "def brownify_augmentation(image, alpha=0.5):\n",
    "    \"\"\" 对棕褐色物品进行颜色增强 \"\"\"\n",
    "    brown_tint = np.array([19, 69, 139], dtype=np.float32)  # 定义棕褐色的色调\n",
    "    image = image.astype(np.float32)  # 将图像转换为浮点数类型\n",
    "    image = (1 - alpha) * image + alpha * brown_tint  # 混合原图像和棕褐色色调\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)  # 裁剪值并转换为8位无符号整数\n",
    "    return image  # 返回增强后的图像\n",
    "\n",
    "def augment_image(image, mask, n_augmentations=1, color_augmentation='pca'):\n",
    "    # 定义数据增强的变换序列\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),  # 水平翻转，概率为50%\n",
    "        A.VerticalFlip(p=0.5),    # 垂直翻转，概率为50%\n",
    "        A.RandomRotate90(p=0.5),  # 随机旋转90度，概率为50%\n",
    "        # A.Transpose(p=0.5),       # 转置操作（交换x和y轴），概率为50%\n",
    "        A.RandomBrightnessContrast(p=0.2),  # 随机调整亮度和对比度，概率为20%\n",
    "        A.ElasticTransform(p=0.2),  # 弹性变换，概率为20%\n",
    "        A.GridDistortion(p=0.2),    # 网格扭曲，概率为20%\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.2),  # 平移、缩放和旋转，概率为20%\n",
    "        # A.RandomCrop(height=256, width=256, p=1.0)  # 随机裁剪到256x256大小，概率为100%\n",
    "    ])\n",
    "    \n",
    "    augmented_images = []  # 存储增强后的图像\n",
    "    augmented_masks = []  # 存储增强后的掩码\n",
    "    \n",
    "    for _ in range(n_augmentations):\n",
    "        augmented = transform(image=image, mask=mask)  # 对图像和掩码进行增强\n",
    "        image_aug = augmented['image']  # 获取增强后的图像\n",
    "        mask_aug = augmented['mask']  # 获取增强后的掩码\n",
    "        \n",
    "        # 应用选择的颜色增强方法\n",
    "        if color_augmentation == 'pca':\n",
    "            image_aug = pca_color_augmentation(image_aug)\n",
    "        elif color_augmentation == 'brownify':\n",
    "            image_aug = brownify_augmentation(image_aug)\n",
    "        \n",
    "        augmented_images.append(image_aug)  # 添加到增强图像列表\n",
    "        augmented_masks.append(mask_aug)  # 添加到增强掩码列表\n",
    "    \n",
    "    return augmented_images, augmented_masks  # 返回增强后的图像和掩码\n",
    "\n",
    "def read_mask(mask_path, label_format):\n",
    "    # 读取掩码文件，根据标签格式选择不同的方法\n",
    "    if label_format == \"mask\":\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)  # 读取PNG格式掩码\n",
    "    elif label_format == \"json\":\n",
    "        with open(mask_path, 'r') as f:\n",
    "            annotations = json.load(f)  # 读取JSON文件\n",
    "            mask = np.zeros((annotations['imageHeight'], annotations['imageWidth']), dtype=np.uint8)  # 创建空白掩码\n",
    "            for shape in annotations['shapes']:\n",
    "                points = np.array(shape['points'], dtype=np.int32)  # 将形状的点转换为数组\n",
    "                cv2.fillPoly(mask, [points], color=(255))  # 用白色填充多边形\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported label format. Use 'mask' or 'json'.\")  # 抛出异常\n",
    "    return mask  # 返回生成的掩码\n",
    "\n",
    "def process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format=\"mask\", n_augmentations=5, color_augmentation='pca'):\n",
    "    # 检查输出文件夹是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "    if not os.path.exists(output_mask_folder):\n",
    "        os.makedirs(output_mask_folder)\n",
    "\n",
    "    image_files = os.listdir(input_image_folder)  # 获取输入图像文件列表\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_image_folder, image_file)  # 构建图像文件路径\n",
    "        \n",
    "        # 根据标签格式选择相应的掩码文件名\n",
    "        if image_path.endswith('.jpg'):\n",
    "            mask_file = image_file.replace('.jpg', '.png') if label_format == \"mask\" else image_file.replace(\n",
    "                '.jpg', '.json')\n",
    "        elif image_path.endswith('.bmp'):\n",
    "            mask_file = image_file.replace('.bmp', '.png') if label_format == \"mask\" else image_file.replace(\n",
    "                '.bmp', '.json')\n",
    "        else:\n",
    "            print(f\"Unsupported image format for {image_path}, skipping.\")\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Label file {mask_path} does not exist, skipping.\")  # 如果掩码文件不存在，跳过该文件\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(image_path)  # 读取图像文件\n",
    "        mask = read_mask(mask_path, label_format)  # 读取掩码文件\n",
    "        \n",
    "        augmented_images, augmented_masks = augment_image(image, mask, n_augmentations, color_augmentation)  # 对图像和掩码进行数据增强\n",
    "        \n",
    "        for i, (image_aug, mask_aug) in enumerate(zip(augmented_images, augmented_masks)):\n",
    "            output_image_path = os.path.join(output_image_folder, f\"{os.path.splitext(image_file)[0]}_aug_{i}.jpg\")  # 输出图像文件路径\n",
    "            output_mask_path = os.path.join(output_mask_folder, f\"{os.path.splitext(mask_file)[0]}_aug_{i}.png\")  # 输出掩码文件路径\n",
    "            \n",
    "            cv2.imwrite(output_image_path, image_aug)  # 保存增强后的图像\n",
    "            cv2.imwrite(output_mask_path, mask_aug)  # 保存增强后的掩码\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_image_folder = r\"H:\\data\\rebar2D\\train\\img\"\n",
    "    input_mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask\"  # 输入掩码文件夹路径\n",
    "    output_image_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img1\"  # 输出图像文件夹路径\n",
    "    output_mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask1\"  # 输出掩码文件夹路径\n",
    "    label_format = \"mask\"  # 标签格式，可选\"mask\"或\"json\"\n",
    "    n_augmentations = 5  # 每张图像增强的数量\n",
    "    color_augmentation = 'brownify'  # 颜色增强方式，可选\"pca\"或\"brownify\"\n",
    "    \n",
    "    process_folder(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, label_format, n_augmentations, color_augmentation)  # 处理文件夹中的文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c85676881b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_files_in_directory(directory_path, file_extension=None):\n",
    "    \"\"\"\n",
    "    对目录中的所有文件进行处理\n",
    "    :param directory_path: 目录路径\n",
    "    :param file_extension: 只处理指定扩展名的文件（例如\".txt\"），默认处理所有文件\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print(f\"{directory_path} is not a valid directory.\")\n",
    "        return\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file_extension is None or file.endswith(file_extension):\n",
    "                file_path = os.path.join(root, file)\n",
    "                process_single_file(file_path)\n",
    "\n",
    "def process_single_file(file_path):\n",
    "    # 在这里处理单个文件的逻辑\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    # 假设你的处理逻辑是读取文件并打印其内容\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        print(content)\n",
    "\n",
    "# 使用示例\n",
    "directory_to_process = '/path/to/your/directory'\n",
    "process_files_in_directory(directory_to_process, file_extension=\".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a98b2e9db078dae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T08:30:27.616491Z",
     "start_time": "2024-06-30T08:30:26.689805Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 45\u001B[0m\n\u001B[0;32m     42\u001B[0m mask_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mwork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mrebar2D\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     43\u001B[0m output_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mwork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mrebar2D\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mTEMP\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 45\u001B[0m batch_process_images(original_folder, mask_folder, output_folder)\n",
      "Cell \u001B[1;32mIn[26], line 37\u001B[0m, in \u001B[0;36mbatch_process_images\u001B[1;34m(original_folder, mask_folder, output_folder)\u001B[0m\n\u001B[0;32m     34\u001B[0m output_image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_folder, original_image_name)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# 应用掩码\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m apply_mask(original_image_path, mask_image_path, output_image_path)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcessed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moriginal_image_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with mask \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmask_image_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[26], line 13\u001B[0m, in \u001B[0;36mapply_mask\u001B[1;34m(original_image_path, mask_image_path, output_image_path)\u001B[0m\n\u001B[0;32m     10\u001B[0m color_mask \u001B[38;5;241m=\u001B[39m ImageOps\u001B[38;5;241m.\u001B[39mcolorize(mask_image, black\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m), white\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m128\u001B[39m))\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 将彩色掩码图像叠加到原图上\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m combined_image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39malpha_composite(original_image, color_mask)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# 保存生成的图像\u001B[39;00m\n\u001B[0;32m     16\u001B[0m combined_image\u001B[38;5;241m.\u001B[39msave(output_image_path)\n",
      "File \u001B[1;32mF:\\work\\environment\\envs\\yolo\\Lib\\site-packages\\PIL\\Image.py:3328\u001B[0m, in \u001B[0;36malpha_composite\u001B[1;34m(im1, im2)\u001B[0m\n\u001B[0;32m   3326\u001B[0m im1\u001B[38;5;241m.\u001B[39mload()\n\u001B[0;32m   3327\u001B[0m im2\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m-> 3328\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m im1\u001B[38;5;241m.\u001B[39m_new(core\u001B[38;5;241m.\u001B[39malpha_composite(im1\u001B[38;5;241m.\u001B[39mim, im2\u001B[38;5;241m.\u001B[39mim))\n",
      "\u001B[1;31mValueError\u001B[0m: images do not match"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "def apply_mask(original_image_path, mask_image_path, output_image_path):\n",
    "    # 打开原图和掩码图像\n",
    "    original_image = Image.open(original_image_path).convert(\"RGBA\")\n",
    "    mask_image = Image.open(mask_image_path).convert(\"L\")  # 转换为灰度图像\n",
    "\n",
    "    # 创建彩色版的掩码图像（例如将其变为红色）\n",
    "    color_mask = ImageOps.colorize(mask_image, black=(0, 0, 0, 0), white=(255, 0, 0, 128))\n",
    "\n",
    "    # 将彩色掩码图像叠加到原图上\n",
    "    combined_image = Image.alpha_composite(original_image, color_mask)\n",
    "\n",
    "    # 保存生成的图像\n",
    "    combined_image.save(output_image_path)\n",
    "\n",
    "def batch_process_images(original_folder, mask_folder, output_folder):\n",
    "    # 确保输出文件夹存在\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 获取原图和掩码图像文件名\n",
    "    original_images = [f for f in os.listdir(original_folder) if f.endswith(('jpg', 'bmp'))]\n",
    "    mask_images = [f for f in os.listdir(mask_folder) if f.endswith('png')]\n",
    "\n",
    "    for original_image_name in original_images:\n",
    "        # 对应的掩码图像文件名\n",
    "        mask_image_name = original_image_name.rsplit('.', 1)[0] + '.png'\n",
    "\n",
    "        if mask_image_name in mask_images:\n",
    "            original_image_path = os.path.join(original_folder, original_image_name)\n",
    "            mask_image_path = os.path.join(mask_folder, mask_image_name)\n",
    "            output_image_path = os.path.join(output_folder, original_image_name)\n",
    "\n",
    "            # 应用掩码\n",
    "            apply_mask(original_image_path, mask_image_path, output_image_path)\n",
    "            print(f'Processed {original_image_name} with mask {mask_image_name}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_folder = r\"F:\\work\\dataset\\rebar2D\\train\\img\"\n",
    "    mask_folder = r\"F:\\work\\dataset\\rebar2D\\train\\mask\"\n",
    "    output_folder = r\"F:\\work\\dataset\\rebar2D\\train\\TEMP\"\n",
    "\n",
    "    batch_process_images(original_folder, mask_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602edc29ac9f1119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T03:11:59.012443Z",
     "start_time": "2024-07-01T03:11:57.323311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 F:\\work\\dataset\\rebar2D\\train\\img\\Image_20240622155643472.jpg: 448x640 1 rebar, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Result saved to F:\\work\\dataset\\rebar2D\\train\\TEMP\\test.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 使用YOLOv8模型检测钢筋并分割\n",
    "def detect_rebar(image_path):\n",
    "    model = YOLO(r\"F:\\work\\python\\clone\\2d\\ultralnew\\ultralytics\\best1.pt\")  # 替换为你的YOLOv8分割模型路径\n",
    "    results = model(image_path)\n",
    "\n",
    "    # 获取分割结果的边界框\n",
    "    boxes = results[0].boxes.cpu().numpy()  # 假设返回的第一个结果包含边界框\n",
    "\n",
    "    return boxes\n",
    "\n",
    "# 获取边界框四个点并扩大\n",
    "def expand_bbox(bbox, expansion_factor=0.1):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    x1_exp = max(0, x1 - width * expansion_factor)\n",
    "    y1_exp = max(0, y1 - height * expansion_factor)\n",
    "    x2_exp = min(image.shape[1], x2 + width * expansion_factor)\n",
    "    y2_exp = min(image.shape[0], y2 + height * expansion_factor)\n",
    "\n",
    "    return int(x1_exp), int(y1_exp), int(x2_exp), int(y2_exp)\n",
    "\n",
    "# 提取扩大后的边界框内容\n",
    "def extract_expanded_bbox_content(image, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "# 使用传统方法获得钢筋的轮廓\n",
    "def get_rebar_contour(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # 找到轮廓\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "# 将轮廓写入和原图同大小的画布中并保存\n",
    "def draw_contours_on_canvas(image, contours, bbox, output_path):\n",
    "    canvas = np.zeros_like(image)\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    for contour in contours:\n",
    "        contour += np.array([x1, y1])\n",
    "        cv2.drawContours(canvas, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    cv2.imwrite(output_path, canvas)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path = r\"F:\\work\\dataset\\rebar2D\\train\\img\\Image_20240622155643472.jpg\"  # 输入图像路径\n",
    "    output_path = r\"F:\\work\\dataset\\rebar2D\\train\\TEMP\\test.jpg\"  # 输出图像路径\n",
    "\n",
    "    # 读取图像\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # 检测钢筋并获取边界框\n",
    "    boxes = detect_rebar(image_path)\n",
    "\n",
    "    # 假设只有一个钢筋对象，获取其边界框并扩大\n",
    "    bbox = boxes[0].xyxy[0]\n",
    "    expanded_bbox = expand_bbox(bbox)\n",
    "\n",
    "    # 提取扩大后的边界框内容\n",
    "    expanded_bbox_content = extract_expanded_bbox_content(image, expanded_bbox)\n",
    "\n",
    "    # 获取钢筋的轮廓\n",
    "    contours = get_rebar_contour(expanded_bbox_content)\n",
    "\n",
    "    # 将轮廓写入和原图同大小的画布中并保存\n",
    "    draw_contours_on_canvas(image, contours, expanded_bbox, output_path)\n",
    "    print(f'Result saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3dd12b3d18d16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device opened successfully\n",
      "Current resolution: Width = 3072, Height = 2048\n",
      "Current pixel format: 0x110000d\n",
      "Resolution and pixel format set successfully\n",
      "Get one frame: Width[1920], Height[1080], FrameNum[1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4147200 into shape (1080,1920,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 141\u001B[0m\n\u001B[0;32m    138\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 141\u001B[0m     main()\n",
      "Cell \u001B[1;32mIn[1], line 111\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;66;03m# 确定图像形状，根据像素格式调整通道数\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_pixel_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x110000d\u001B[39m:  \u001B[38;5;66;03m# RGB8\u001B[39;00m\n\u001B[1;32m--> 111\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mreshape((stFrameInfo\u001B[38;5;241m.\u001B[39mnHeight, stFrameInfo\u001B[38;5;241m.\u001B[39mnWidth, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m new_pixel_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x1080009\u001B[39m:  \u001B[38;5;66;03m# Mono8\u001B[39;00m\n\u001B[0;32m    113\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mreshape((stFrameInfo\u001B[38;5;241m.\u001B[39mnHeight, stFrameInfo\u001B[38;5;241m.\u001B[39mnWidth))\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 4147200 into shape (1080,1920,3)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ctypes import *\n",
    "\n",
    "# 添加 MVS SDK 的 Python 包路径\n",
    "sys.path.append(r\"F:\\install\\MVS\\Development\\Samples\\Python\\MvImport\")\n",
    "\n",
    "# 导入 MVS SDK\n",
    "from MvCameraControl_class import *\n",
    "\n",
    "def main():\n",
    "    # 创建相机对象\n",
    "    cam = MvCamera()\n",
    "\n",
    "    # 设备信息列表\n",
    "    deviceList = MV_CC_DEVICE_INFO_LIST()\n",
    "    tlayerType = MV_GIGE_DEVICE | MV_USB_DEVICE\n",
    "\n",
    "    # 枚举设备\n",
    "    ret = cam.MV_CC_EnumDevices(tlayerType, deviceList)\n",
    "    if ret != 0:\n",
    "        print(f\"Enum devices failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    if deviceList.nDeviceNum == 0:\n",
    "        print(\"No devices found!\")\n",
    "        return\n",
    "\n",
    "    # 选择第一个设备\n",
    "    stDeviceList = cast(deviceList.pDeviceInfo[0], POINTER(MV_CC_DEVICE_INFO)).contents\n",
    "\n",
    "    # 创建句柄\n",
    "    ret = cam.MV_CC_CreateHandle(stDeviceList)\n",
    "    if ret != 0:\n",
    "        print(f\"Create handle failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    # 打开设备\n",
    "    ret = cam.MV_CC_OpenDevice(MV_ACCESS_Exclusive, 0)\n",
    "    if ret != 0:\n",
    "        print(f\"Open device failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(\"Device opened successfully\")\n",
    "\n",
    "    # 获取并打印当前分辨率\n",
    "    width = MVCC_INTVALUE()\n",
    "    height = MVCC_INTVALUE()\n",
    "    ret = cam.MV_CC_GetIntValue(\"Width\", width)\n",
    "    if ret != 0:\n",
    "        print(f\"Get width failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "    ret = cam.MV_CC_GetIntValue(\"Height\", height)\n",
    "    if ret != 0:\n",
    "        print(f\"Get height failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(f\"Current resolution: Width = {width.nCurValue}, Height = {height.nCurValue}\")\n",
    "\n",
    "    # 获取并打印当前像素格式\n",
    "    stEnumValue = MVCC_ENUMVALUE()\n",
    "    ret = cam.MV_CC_GetEnumValue(\"PixelFormat\", stEnumValue)\n",
    "    if ret != 0:\n",
    "        print(f\"Get pixel format failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(f\"Current pixel format: 0x{stEnumValue.nCurValue:x}\")\n",
    "\n",
    "    # 设置新的分辨率和像素格式（根据需要进行调整）\n",
    "    new_width = 1920\n",
    "    new_height = 1080\n",
    "    new_pixel_format = 0x110000d  # 替换为你想使用的像素格式\n",
    "\n",
    "    ret = cam.MV_CC_SetIntValue(\"Width\", new_width)\n",
    "    if ret != 0:\n",
    "        print(f\"Set width failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    ret = cam.MV_CC_SetIntValue(\"Height\", new_height)\n",
    "    if ret != 0:\n",
    "        print(f\"Set height failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    ret = cam.MV_CC_SetEnumValue(\"PixelFormat\", new_pixel_format)\n",
    "    if ret != 0:\n",
    "        print(f\"Set pixel format failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(\"Resolution and pixel format set successfully\")\n",
    "\n",
    "    # 开始采集\n",
    "    ret = cam.MV_CC_StartGrabbing()\n",
    "    if ret != 0:\n",
    "        print(f\"Start grabbing failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    data_buf = None\n",
    "    buf_size = new_width * new_height * 3  # RGB8 格式缓冲区大小\n",
    "    while True:\n",
    "        stFrameInfo = MV_FRAME_OUT_INFO_EX()\n",
    "        data_buf = (c_ubyte * buf_size)()\n",
    "        ret = cam.MV_CC_GetOneFrameTimeout(data_buf, buf_size, stFrameInfo, 1000)\n",
    "        if ret == 0:\n",
    "            print(f\"Get one frame: Width[{stFrameInfo.nWidth}], Height[{stFrameInfo.nHeight}], FrameNum[{stFrameInfo.nFrameNum}]\")\n",
    "            img_buff = (c_ubyte * stFrameInfo.nFrameLen).from_address(addressof(data_buf))\n",
    "            img = np.frombuffer(img_buff, dtype=np.uint8)\n",
    "\n",
    "            # 确定图像形状，根据像素格式调整通道数\n",
    "            if new_pixel_format == 0x110000d:  # RGB8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth, 3))\n",
    "            elif new_pixel_format == 0x1080009:  # Mono8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth))\n",
    "            elif new_pixel_format in {0x10c0027, 0x10c002b}:  # BayerRG8, BayerGB8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BAYER_RG2RGB if new_pixel_format == 0x10c0027 else cv2.COLOR_BAYER_BG2RGB)\n",
    "            elif new_pixel_format == 0x1100011:  # YUV422Packed\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth, 2))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_YUV2BGR_YUYV)\n",
    "            else:\n",
    "                print(\"Unsupported pixel format\")\n",
    "                break\n",
    "\n",
    "            # 显示图像\n",
    "            cv2.imshow('Camera', img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Get image failed! ret[0x{ret:x}]\")\n",
    "            break\n",
    "\n",
    "    # 停止采集\n",
    "    cam.MV_CC_StopGrabbing()\n",
    "    cam.MV_CC_CloseDevice()\n",
    "    cam.MV_CC_DestroyHandle()\n",
    "\n",
    "    # 释放资源\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a72e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device opened successfully\n",
      "Current resolution: Width = 1920, Height = 1080\n",
      "Current pixel format: 0x110000d\n",
      "Resolution and pixel format set successfully\n",
      "Get one frame: Width[1920], Height[1080], FrameNum[1649]\n",
      "Frame length: 4147200\n",
      "Image buffer size: 4147200\n",
      "Expected buffer size: 6220800\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4147200 into shape (1080,1920,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 145\u001B[0m\n\u001B[0;32m    142\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 145\u001B[0m     main()\n",
      "Cell \u001B[1;32mIn[1], line 115\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# 确定图像形状，根据像素格式调整通道数\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_pixel_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x110000d\u001B[39m:  \u001B[38;5;66;03m# RGB8\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mreshape((stFrameInfo\u001B[38;5;241m.\u001B[39mnHeight, stFrameInfo\u001B[38;5;241m.\u001B[39mnWidth, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m new_pixel_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x1080009\u001B[39m:  \u001B[38;5;66;03m# Mono8\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mreshape((stFrameInfo\u001B[38;5;241m.\u001B[39mnHeight, stFrameInfo\u001B[38;5;241m.\u001B[39mnWidth))\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 4147200 into shape (1080,1920,3)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ctypes import *\n",
    "\n",
    "# 添加 MVS SDK 的 Python 包路径\n",
    "sys.path.append(r\"F:\\install\\MVS\\Development\\Samples\\Python\\MvImport\")\n",
    "\n",
    "# 导入 MVS SDK\n",
    "from MvCameraControl_class import *\n",
    "\n",
    "def main():\n",
    "    # 创建相机对象\n",
    "    cam = MvCamera()\n",
    "\n",
    "    # 设备信息列表\n",
    "    deviceList = MV_CC_DEVICE_INFO_LIST()\n",
    "    tlayerType = MV_GIGE_DEVICE | MV_USB_DEVICE\n",
    "\n",
    "    # 枚举设备\n",
    "    ret = cam.MV_CC_EnumDevices(tlayerType, deviceList)\n",
    "    if ret != 0:\n",
    "        print(f\"Enum devices failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    if deviceList.nDeviceNum == 0:\n",
    "        print(\"No devices found!\")\n",
    "        return\n",
    "\n",
    "    # 选择第一个设备\n",
    "    stDeviceList = cast(deviceList.pDeviceInfo[0], POINTER(MV_CC_DEVICE_INFO)).contents\n",
    "\n",
    "    # 创建句柄\n",
    "    ret = cam.MV_CC_CreateHandle(stDeviceList)\n",
    "    if ret != 0:\n",
    "        print(f\"Create handle failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    # 打开设备\n",
    "    ret = cam.MV_CC_OpenDevice(MV_ACCESS_Exclusive, 0)\n",
    "    if ret != 0:\n",
    "        print(f\"Open device failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(\"Device opened successfully\")\n",
    "\n",
    "    # 获取并打印当前分辨率\n",
    "    width = MVCC_INTVALUE()\n",
    "    height = MVCC_INTVALUE()\n",
    "    ret = cam.MV_CC_GetIntValue(\"Width\", width)\n",
    "    if ret != 0:\n",
    "        print(f\"Get width failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "    ret = cam.MV_CC_GetIntValue(\"Height\", height)\n",
    "    if ret != 0:\n",
    "        print(f\"Get height failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(f\"Current resolution: Width = {width.nCurValue}, Height = {height.nCurValue}\")\n",
    "\n",
    "    # 获取并打印当前像素格式\n",
    "    stEnumValue = MVCC_ENUMVALUE()\n",
    "    ret = cam.MV_CC_GetEnumValue(\"PixelFormat\", stEnumValue)\n",
    "    if ret != 0:\n",
    "        print(f\"Get pixel format failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(f\"Current pixel format: 0x{stEnumValue.nCurValue:x}\")\n",
    "\n",
    "    # 设置新的分辨率和像素格式（根据需要进行调整）\n",
    "    new_width = 1920\n",
    "    new_height = 1080\n",
    "    new_pixel_format = 0x110000d  # 替换为你想使用的像素格式\n",
    "\n",
    "    ret = cam.MV_CC_SetIntValue(\"Width\", new_width)\n",
    "    if ret != 0:\n",
    "        print(f\"Set width failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    ret = cam.MV_CC_SetIntValue(\"Height\", new_height)\n",
    "    if ret != 0:\n",
    "        print(f\"Set height failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    ret = cam.MV_CC_SetEnumValue(\"PixelFormat\", new_pixel_format)\n",
    "    if ret != 0:\n",
    "        print(f\"Set pixel format failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(\"Resolution and pixel format set successfully\")\n",
    "\n",
    "    # 开始采集\n",
    "    ret = cam.MV_CC_StartGrabbing()\n",
    "    if ret != 0:\n",
    "        print(f\"Start grabbing failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    data_buf = None\n",
    "    buf_size = new_width * new_height * 3  # RGB8 格式缓冲区大小\n",
    "    while True:\n",
    "        stFrameInfo = MV_FRAME_OUT_INFO_EX()\n",
    "        data_buf = (c_ubyte * buf_size)()\n",
    "        ret = cam.MV_CC_GetOneFrameTimeout(data_buf, buf_size, stFrameInfo, 1000)\n",
    "        if ret == 0:\n",
    "            print(f\"Get one frame: Width[{stFrameInfo.nWidth}], Height[{stFrameInfo.nHeight}], FrameNum[{stFrameInfo.nFrameNum}]\")\n",
    "            print(f\"Frame length: {stFrameInfo.nFrameLen}\")\n",
    "            img_buff = (c_ubyte * stFrameInfo.nFrameLen).from_address(addressof(data_buf))\n",
    "            img = np.frombuffer(img_buff, dtype=np.uint8)\n",
    "\n",
    "            print(f\"Image buffer size: {img.size}\")\n",
    "            print(f\"Expected buffer size: {new_width * new_height * 3}\")\n",
    "\n",
    "            # 确定图像形状，根据像素格式调整通道数\n",
    "            if new_pixel_format == 0x110000d:  # RGB8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth, 3))\n",
    "            elif new_pixel_format == 0x1080009:  # Mono8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth))\n",
    "            elif new_pixel_format in {0x10c0027, 0x10c002b}:  # BayerRG8, BayerGB8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BAYER_RG2RGB if new_pixel_format == 0x10c0027 else cv2.COLOR_BAYER_BG2RGB)\n",
    "            elif new_pixel_format == 0x1100011:  # YUV422Packed\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth, 2))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_YUV2BGR_YUYV)\n",
    "            else:\n",
    "                print(\"Unsupported pixel format\")\n",
    "                break\n",
    "\n",
    "            # 显示图像\n",
    "            cv2.imshow('Camera', img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Get image failed! ret[0x{ret:x}]\")\n",
    "            break\n",
    "\n",
    "    # 停止采集\n",
    "    cam.MV_CC_StopGrabbing()\n",
    "    cam.MV_CC_CloseDevice()\n",
    "    cam.MV_CC_DestroyHandle()\n",
    "\n",
    "    # 释放资源\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad23ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device opened successfully\n",
      "Current resolution: Width = 1920, Height = 1080\n",
      "Current pixel format: 0x110000d\n",
      "Resolution and pixel format set successfully\n",
      "Get one frame: Width[3072], Height[2048], FrameNum[2410]\n",
      "Frame length: 12582912\n",
      "Image buffer size: 12582912\n",
      "Expected buffer size: 18874368\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12582912 into shape (2048,3072,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 145\u001B[0m\n\u001B[0;32m    142\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 145\u001B[0m     main()\n",
      "Cell \u001B[1;32mIn[1], line 115\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# 确定图像形状，根据像素格式调整通道数\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_pixel_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x110000d\u001B[39m:  \u001B[38;5;66;03m# RGB8\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mreshape((stFrameInfo\u001B[38;5;241m.\u001B[39mnHeight, stFrameInfo\u001B[38;5;241m.\u001B[39mnWidth, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m new_pixel_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x1080009\u001B[39m:  \u001B[38;5;66;03m# Mono8\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mreshape((stFrameInfo\u001B[38;5;241m.\u001B[39mnHeight, stFrameInfo\u001B[38;5;241m.\u001B[39mnWidth))\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 12582912 into shape (2048,3072,3)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ctypes import *\n",
    "\n",
    "# 添加 MVS SDK 的 Python 包路径\n",
    "sys.path.append(r\"F:\\install\\MVS\\Development\\Samples\\Python\\MvImport\")\n",
    "\n",
    "# 导入 MVS SDK\n",
    "from MvCameraControl_class import *\n",
    "\n",
    "def main():\n",
    "    # 创建相机对象\n",
    "    cam = MvCamera()\n",
    "\n",
    "    # 设备信息列表\n",
    "    deviceList = MV_CC_DEVICE_INFO_LIST()\n",
    "    tlayerType = MV_GIGE_DEVICE | MV_USB_DEVICE\n",
    "\n",
    "    # 枚举设备\n",
    "    ret = cam.MV_CC_EnumDevices(tlayerType, deviceList)\n",
    "    if ret != 0:\n",
    "        print(f\"Enum devices failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    if deviceList.nDeviceNum == 0:\n",
    "        print(\"No devices found!\")\n",
    "        return\n",
    "\n",
    "    # 选择第一个设备\n",
    "    stDeviceList = cast(deviceList.pDeviceInfo[0], POINTER(MV_CC_DEVICE_INFO)).contents\n",
    "\n",
    "    # 创建句柄\n",
    "    ret = cam.MV_CC_CreateHandle(stDeviceList)\n",
    "    if ret != 0:\n",
    "        print(f\"Create handle failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    # 打开设备\n",
    "    ret = cam.MV_CC_OpenDevice(MV_ACCESS_Exclusive, 0)\n",
    "    if ret != 0:\n",
    "        print(f\"Open device failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(\"Device opened successfully\")\n",
    "\n",
    "    # 获取并打印当前分辨率\n",
    "    width = MVCC_INTVALUE()\n",
    "    height = MVCC_INTVALUE()\n",
    "    ret = cam.MV_CC_GetIntValue(\"Width\", width)\n",
    "    if ret != 0:\n",
    "        print(f\"Get width failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "    ret = cam.MV_CC_GetIntValue(\"Height\", height)\n",
    "    if ret != 0:\n",
    "        print(f\"Get height failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(f\"Current resolution: Width = {width.nCurValue}, Height = {height.nCurValue}\")\n",
    "\n",
    "    # 获取并打印当前像素格式\n",
    "    stEnumValue = MVCC_ENUMVALUE()\n",
    "    ret = cam.MV_CC_GetEnumValue(\"PixelFormat\", stEnumValue)\n",
    "    if ret != 0:\n",
    "        print(f\"Get pixel format failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(f\"Current pixel format: 0x{stEnumValue.nCurValue:x}\")\n",
    "\n",
    "    # 设置新的分辨率和像素格式（根据需要进行调整）\n",
    "    new_width = 3072\n",
    "    new_height = 2048\n",
    "    new_pixel_format = 0x110000d  # 替换为你想使用的像素格式\n",
    "\n",
    "    ret = cam.MV_CC_SetIntValue(\"Width\", new_width)\n",
    "    if ret != 0:\n",
    "        print(f\"Set width failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    ret = cam.MV_CC_SetIntValue(\"Height\", new_height)\n",
    "    if ret != 0:\n",
    "        print(f\"Set height failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    ret = cam.MV_CC_SetEnumValue(\"PixelFormat\", new_pixel_format)\n",
    "    if ret != 0:\n",
    "        print(f\"Set pixel format failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    print(\"Resolution and pixel format set successfully\")\n",
    "\n",
    "    # 开始采集\n",
    "    ret = cam.MV_CC_StartGrabbing()\n",
    "    if ret != 0:\n",
    "        print(f\"Start grabbing failed! ret[0x{ret:x}]\")\n",
    "        return\n",
    "\n",
    "    data_buf = None\n",
    "    buf_size = new_width * new_height * 3  # RGB8 格式缓冲区大小\n",
    "    while True:\n",
    "        stFrameInfo = MV_FRAME_OUT_INFO_EX()\n",
    "        data_buf = (c_ubyte * buf_size)()\n",
    "        ret = cam.MV_CC_GetOneFrameTimeout(data_buf, buf_size, stFrameInfo, 1000)\n",
    "        if ret == 0:\n",
    "            print(f\"Get one frame: Width[{stFrameInfo.nWidth}], Height[{stFrameInfo.nHeight}], FrameNum[{stFrameInfo.nFrameNum}]\")\n",
    "            print(f\"Frame length: {stFrameInfo.nFrameLen}\")\n",
    "            img_buff = (c_ubyte * stFrameInfo.nFrameLen).from_address(addressof(data_buf))\n",
    "            img = np.frombuffer(img_buff, dtype=np.uint8)\n",
    "\n",
    "            print(f\"Image buffer size: {img.size}\")\n",
    "            print(f\"Expected buffer size: {new_width * new_height * 3}\")\n",
    "\n",
    "            # 确定图像形状，根据像素格式调整通道数\n",
    "            if new_pixel_format == 0x110000d:  # RGB8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth, 3))\n",
    "            elif new_pixel_format == 0x1080009:  # Mono8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth))\n",
    "            elif new_pixel_format in {0x10c0027, 0x10c002b}:  # BayerRG8, BayerGB8\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BAYER_RG2RGB if new_pixel_format == 0x10c0027 else cv2.COLOR_BAYER_BG2RGB)\n",
    "            elif new_pixel_format == 0x1100011:  # YUV422Packed\n",
    "                img = img.reshape((stFrameInfo.nHeight, stFrameInfo.nWidth, 2))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_YUV2BGR_YUYV)\n",
    "            else:\n",
    "                print(\"Unsupported pixel format\")\n",
    "                break\n",
    "\n",
    "            # 显示图像\n",
    "            cv2.imshow('Camera', img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Get image failed! ret[0x{ret:x}]\")\n",
    "            break\n",
    "\n",
    "    # 停止采集\n",
    "    cam.MV_CC_StopGrabbing()\n",
    "    cam.MV_CC_CloseDevice()\n",
    "    cam.MV_CC_DestroyHandle()\n",
    "\n",
    "    # 释放资源\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ea935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
