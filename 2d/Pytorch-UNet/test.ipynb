{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "import ",
   "id": "26ce96feff5efd44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T09:34:04.714Z",
     "start_time": "2024-06-25T09:34:04.683540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "img = Image.open(r'F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\sample\\Image_20240622155143140_OUT.png')\n",
    "print(img)"
   ],
   "id": "5fea526b9bc10cc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=1 size=3072x2048 at 0x1457B1B0CD0>\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T11:01:07.686216Z",
     "start_time": "2024-06-25T11:01:07.667617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "img1=cv2.imread(r'F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\sample\\barsample1_OUT.png')\n",
    "print(img1)"
   ],
   "id": "70627fb4f3020698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T09:36:44.108757Z",
     "start_time": "2024-06-25T09:36:41.848414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data_loading import BasicDataset\n",
    "from unet import UNet\n",
    "from utils.utils import plot_img_and_mask\n",
    "\n",
    "def predict_img(net, full_img, device, scale_factor=1, out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "    logging.info(f'Preprocessed image shape: {img.shape}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "        output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "    logging.info(f'Predicted mask unique values: {torch.unique(mask)}')\n",
    "    return mask[0].long().squeeze().numpy()\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Predict masks from input images')\n",
    "    parser.add_argument('--model', '-m', default='2d/Pytorch-UNet/model/checkpoint_epoch10.pth', metavar='FILE',\n",
    "                        help='Specify the file in which the model is stored')\n",
    "    parser.add_argument('--input', '-i', metavar='INPUT', nargs='+', help='Filenames of input images')\n",
    "    parser.add_argument('--output', '-o', metavar='OUTPUT', nargs='+', help='Filenames of output images')\n",
    "    parser.add_argument('--viz', '-v', action='store_true',\n",
    "                        help='Visualize the images as they are processed')\n",
    "    parser.add_argument('--no-save', '-n', action='store_true', help='Do not save the output masks')\n",
    "    parser.add_argument('--mask-threshold', '-t', type=float, default=0.5,\n",
    "                        help='Minimum probability value to consider a mask pixel white')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5,\n",
    "                        help='Scale factor for the input images')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.input is None:\n",
    "        args.input = [r'F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\barsample.jpg']\n",
    "\n",
    "    return args\n",
    "\n",
    "def get_output_filenames(args):\n",
    "    def _generate_name(fn):\n",
    "        return f'{os.path.splitext(fn)[0]}_OUT.png'\n",
    "    return args.output or list(map(_generate_name, args.input))\n",
    "\n",
    "def mask_to_image(mask: np.ndarray, mask_values):\n",
    "    logging.info(f'Mask shape: {mask.shape}, unique values: {np.unique(mask)}')\n",
    "    if isinstance(mask_values[0], list):\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1], len(mask_values[0])), dtype=np.uint8)\n",
    "    elif mask_values == [0, 1]:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=bool)\n",
    "    else:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.uint8)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = np.argmax(mask, axis=0)\n",
    "\n",
    "    for i, v in enumerate(mask_values):\n",
    "        out[mask == i] = v\n",
    "\n",
    "    return Image.fromarray(out)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "\n",
    "    img_dir = r\"F:\\work\\python\\clone\\2d\\Pytorch-UNet\\data\\imgs\\sample\"\n",
    "    fname = os.listdir(img_dir)\n",
    "    for name in fname:\n",
    "        fname2 = os.path.join(img_dir, name)\n",
    "        if args.input is None:\n",
    "            args.input = [fname2]\n",
    "        else:\n",
    "            args.input.append(fname2)\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "    in_files = args.input\n",
    "    out_files = get_output_filenames(args)\n",
    "\n",
    "    net = UNet(n_channels=3, n_classes=args.classes, bilinear=args.bilinear)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Loading model {args.model}')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    state_dict = torch.load(args.model, map_location=device)\n",
    "    logging.info(f'Model loaded with parameters: {list(net.parameters())[0].data}')\n",
    "    mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    logging.info('Model loaded!')\n",
    "\n",
    "    for i, filename in enumerate(in_files):\n",
    "        logging.info(f'Predicting image {filename} ...')\n",
    "        img = Image.open(filename)\n",
    "\n",
    "        mask = predict_img(net=net,\n",
    "                           full_img=img,\n",
    "                           scale_factor=args.scale,\n",
    "                           out_threshold=args.mask_threshold,\n",
    "                           device=device)\n",
    "\n"
   ],
   "id": "1e148cb4cff4caca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model FILE] [--input INPUT [INPUT ...]]\n",
      "                             [--output OUTPUT [OUTPUT ...]] [--viz]\n",
      "                             [--no-save] [--mask-threshold MASK_THRESHOLD]\n",
      "                             [--scale SCALE] [--bilinear] [--classes CLASSES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Liminghui\\AppData\\Roaming\\jupyter\\runtime\\kernel-b15d4986-7d81-481e-a485-73882b6175e1.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\work\\environment\\envs\\bar\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc554255b9ec99d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
