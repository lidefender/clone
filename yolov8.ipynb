{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8839816,"sourceType":"datasetVersion","datasetId":5319959},{"sourceId":8840887,"sourceType":"datasetVersion","datasetId":5299284},{"sourceId":71525,"sourceType":"modelInstanceVersion","modelInstanceId":58686}],"dockerImageVersionId":30357,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div align=\"center\">\n\n  <a href=\"https://ultralytics.com/yolov8\" target=\"_blank\">\n    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n\n\n<br>\n  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n  <a href=\"https://www.kaggle.com/ultralytics/yolov8\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n<br>\n\nWelcome to the Ultralytics YOLOv8 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLOv8</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLOv8 and understand its features and capabilities.\n\nYOLOv8 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n\nWe hope that the resources in this notebook will help you get the most out of YOLOv8. Please browse the YOLOv8 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n\n</div>","metadata":{"id":"t6MPjfT5NrKQ"}},{"cell_type":"markdown","source":"# Setup\n\nPip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware.","metadata":{"id":"7mGmQbAO5pQb"}},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"id":"wbvMlHd_QwMG","outputId":"27ca383c-0a97-4679-f1c5-ba843f033de7","execution":{"iopub.status.busy":"2024-07-02T15:21:48.870277Z","iopub.execute_input":"2024-07-02T15:21:48.871245Z","iopub.status.idle":"2024-07-02T15:22:12.460419Z","shell.execute_reply.started":"2024-07-02T15:21:48.871200Z","shell.execute_reply":"2024-07-02T15:22:12.459246Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Ultralytics YOLOv8.0.145 üöÄ Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nSetup complete ‚úÖ (4 CPUs, 31.4 GB RAM, 5689.6/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1. Predict\n\nYOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLOv8 Predict Docs](https://docs.ultralytics.com/modes/train/).\n","metadata":{"id":"4JnkELT0cIJg"}},{"cell_type":"code","source":"# Run inference on an image with YOLOv8n\n!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'","metadata":{"id":"zR9ZbuQCH7FX","outputId":"64489d1f-e71a-44b5-92f6-2088781ca096"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">","metadata":{"id":"hkAzDWJ7cWTr"}},{"cell_type":"markdown","source":"# 2. Val\nValidate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLOv8 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLOv8 Val Docs](https://docs.ultralytics.com/modes/val/) for more information.","metadata":{"id":"0eq1SMWl6Sfn"}},{"cell_type":"code","source":"# Download COCO val\nimport torch\ntorch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip","metadata":{"id":"WQPtK1QYVaD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validate YOLOv8n on COCO8 val\n!yolo val model=yolov8n.pt data=coco8.yaml","metadata":{"id":"X58w8JLpMnjH","outputId":"e3aacd98-ceca-49b7-e112-a0c25979ad6c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Train\n\n<p align=\"\"><a href=\"https://bit.ly/ultralytics_hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n\nTrain YOLOv8 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLOv8 Train Docs](https://docs.ultralytics.com/modes/train/) for more information.","metadata":{"id":"ZY2VXXXu74w5"}},{"cell_type":"code","source":"# Train YOLOv8n on COCO8 for 3 epochs\n!yolo train model=yolov8n.pt data=coco8.yaml epochs=3 imgsz=640","metadata":{"id":"1NcFxRcFdJ_O","outputId":"b750f2fe-c4d9-4764-b8d5-ed7bd920697b","execution":{"iopub.status.busy":"2024-06-28T12:00:56.963031Z","iopub.execute_input":"2024-06-28T12:00:56.963450Z","iopub.status.idle":"2024-06-28T12:00:57.933847Z","shell.execute_reply.started":"2024-06-28T12:00:56.963413Z","shell.execute_reply":"2024-06-28T12:00:57.932721Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/bin/bash: yolo: command not found\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-07-02T13:01:35.606122Z","iopub.execute_input":"2024-07-02T13:01:35.607095Z","iopub.status.idle":"2024-07-02T13:01:36.967423Z","shell.execute_reply.started":"2024-07-02T13:01:35.607048Z","shell.execute_reply":"2024-07-02T13:01:36.966239Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 1111111111111111111111111111111111111","metadata":{}},{"cell_type":"code","source":"! yolo segment train data=/kaggle/input/rebaryolo/rebar2dkaggle.yaml model=/kaggle/working/runs/segment/train/weights/epoch80.pt epochs=200 imgsz=640 batch=28 save_period=80 device=0,1 patience=50 scale=1","metadata":{"execution":{"iopub.status.busy":"2024-07-02T15:23:39.138070Z","iopub.execute_input":"2024-07-02T15:23:39.138489Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"New https://pypi.org/project/ultralytics/8.2.48 available üòÉ Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145 üöÄ Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                       CUDA:1 (Tesla T4, 15102MiB)\nWARNING ‚ö†Ô∏è Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/runs/segment/train/weights/epoch80.pt, data=/kaggle/input/rebaryolo/rebar2dkaggle.yaml, epochs=200, patience=50, batch=28, imgsz=640, save=True, save_period=80, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=1, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train2\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 22.9MB/s]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1  12318134  ultralytics.nn.modules.head.Segment          [2, 32, 320, [320, 640, 640]] \nYOLOv8x-seg summary: 401 layers, 71752774 parameters, 71752758 gradients\n\nTransferred 657/657 items from pretrained weights\nDDP command: ['/opt/conda/bin/python', '-m', 'torch.distributed.run', '--nproc_per_node', '2', '--master_port', '56817', '/root/.config/Ultralytics/DDP/_temp_s32hv6gs137861832072528.py']\nWARNING ‚ö†Ô∏è Upgrade to torch>=2.0.0 for deterministic training.\nDDP info: RANK 0, WORLD_SIZE 2, DEVICE cuda:0\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train2', view at http://localhost:6006/\nTransferred 657/657 items from pretrained weights\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/rebaryolo/rebar2d/yolodataset/train... 802 images,\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/rebaryolo/rebar2d/yolodataset is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/rebaryolo/rebar2d/yolodataset/val... 69 images, 0 ba\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/rebaryolo/rebar2d/yolodataset/train... 249 images,\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/rebaryolo/rebar2d/yolodataset is not writeable, cache not saved.\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/rebaryolo/rebar2d/yolodataset/train... 802 images,\u001b[0m\nPlotting labels to runs/segment/train2/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 106 weight(decay=0.0), 117 weight(decay=0.0004375), 116 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/segment/train2\u001b[0m\nStarting training for 200 epochs...\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n     82/200      14.2G     0.7683     0.6244     0.5766      0.925         45   ","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Export\n\nExport a YOLOv8 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLOv8 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n\n- üí° ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n- üí° ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n\n\n| Format                                                             | `format` Argument | Model                     | Metadata | Arguments                                           |\n|--------------------------------------------------------------------|-------------------|---------------------------|----------|-----------------------------------------------------|\n| [PyTorch](https://pytorch.org/)                                    | -                 | `yolov8n.pt`              | ‚úÖ        | -                                                   |\n| [TorchScript](https://pytorch.org/docs/stable/jit.html)            | `torchscript`     | `yolov8n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`                                 |\n| [ONNX](https://onnx.ai/)                                           | `onnx`            | `yolov8n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     |\n| [OpenVINO](https://docs.openvino.ai/latest/index.html)             | `openvino`        | `yolov8n_openvino_model/` | ‚úÖ        | `imgsz`, `half`                                     |\n| [TensorRT](https://developer.nvidia.com/tensorrt)                  | `engine`          | `yolov8n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` |\n| [CoreML](https://github.com/apple/coremltools)                     | `coreml`          | `yolov8n.mlmodel`         | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`                      |\n| [TF SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`     | `yolov8n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`                                    |\n| [TF GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`              | `yolov8n.pb`              | ‚ùå        | `imgsz`                                             |\n| [TF Lite](https://www.tensorflow.org/lite)                         | `tflite`          | `yolov8n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`                             |\n| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`         | `yolov8n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                             |\n| [TF.js](https://www.tensorflow.org/js)                             | `tfjs`            | `yolov8n_web_model/`      | ‚úÖ        | `imgsz`                                             |\n| [PaddlePaddle](https://github.com/PaddlePaddle)                    | `paddle`          | `yolov8n_paddle_model/`   | ‚úÖ        | `imgsz`                                             |\n| [ncnn](https://github.com/Tencent/ncnn)                            | `ncnn`            | `yolov8n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`                                     |\n","metadata":{"id":"nPZZeNrLCQG6"}},{"cell_type":"code","source":"!yolo export model=yolov8n.pt format=torchscript","metadata":{"id":"CYIjW4igCjqD","outputId":"2b65e381-717b-4a6f-d6f5-5254c867f3a4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Python Usage\n\nYOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLOv8 Python Docs](https://docs.ultralytics.com/usage/python/).","metadata":{"id":"kUMOQ0OeDBJG"}},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('yolov8n.yaml')  # build a new model from scratch\nmodel = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n\n# Use the model\nresults = model.train(data='coco128.yaml', epochs=3)  # train the model\nresults = model.val()  # evaluate model performance on the validation set\nresults = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\nresults = model.export(format='onnx')  # export the model to ONNX format","metadata":{"id":"bpF9-vS_DAaf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Tasks\n\nYOLOv8 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLOv8 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n\n<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n","metadata":{"id":"Phm9ccmOKye5"}},{"cell_type":"markdown","source":"## 1. Detection\n\nYOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n","metadata":{"id":"yq26lwpYK1lq"}},{"cell_type":"code","source":"# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\nmodel.train(data='coco128.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"8Go5qqS9LbC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Segmentation\n\nYOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n","metadata":{"id":"7ZW58jUzK66B"}},{"cell_type":"code","source":"# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\nmodel.train(data='coco128-seg.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"WFPJIQl_L5HT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Classification\n\nYOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n","metadata":{"id":"ax3p94VNK9zR"}},{"cell_type":"code","source":"# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\nmodel.train(data='mnist160', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"5q9Zu6zlL5rS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Pose\n\nYOLOv8 _pose_ models use the `-pose` suffix, i.e. `yolov8n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details.","metadata":{"id":"SpIaFLiO11TG"}},{"cell_type":"code","source":"# Load YOLOv8n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n classification model\nmodel.train(data='coco8-pose.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"si4aKFNg19vX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Appendix\n\nAdditional content below.","metadata":{"id":"IEijrePND_2I"}},{"cell_type":"code","source":"# Git clone and run tests on updates branch\n!git clone https://github.com/ultralytics/ultralytics -b main\n%pip install -qe ultralytics","metadata":{"id":"uRKlwxSJdhd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run tests (Git clone only)\n!pytest ultralytics/tests","metadata":{"id":"GtPlh7mcCGZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validate multiple models\nfor x in 'nsmlx':\n  !yolo val model=yolov8{x}.pt data=coco.yaml","metadata":{"id":"Wdc6t_bfzDDk"},"execution_count":null,"outputs":[]}]}